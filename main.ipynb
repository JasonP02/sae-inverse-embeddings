{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a080c-1789-4c53-af3d-cb667f9940ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/j/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# %% Load Models \n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "# from hook_sae import HookedSAETransformer\n",
    "# from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "# from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"pythia-70m-deduped-mlp-sm\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = \"blocks.3.hook_mlp_out\", # won't always be a hook point\n",
    "    device = device\n",
    ")\n",
    "\n",
    "pythia: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"EleutherAI/pythia-70m-deduped\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c499a1f-8262-4acc-89a2-8cc4523bf21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard model: top prediction = ' priority', prob = 11.90%\n",
      "SAE reconstruction: top prediction = ' priority', prob = 7.77%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Output Comparison with and without SAEs\n",
    "\n",
    "'''\n",
    "Here we can compare the performance of the model with and without SAEs.\n",
    "'''\n",
    "\n",
    "prompt = \"Mitigating the risk of extinction from AI should be a global\"\n",
    "answer = \" priority\"\n",
    "\n",
    "# Commented out, but shows output of the model with and without SAEs\n",
    "\n",
    "# # First see how the model does without SAEs\n",
    "# utils.test_prompt(prompt, answer, pythia)\n",
    "\n",
    "# # Test our prompt, to see what the model says\n",
    "# with pythia.saes(saes=[sae]):\n",
    "#     utils.test_prompt(prompt, answer, pythia)\n",
    "\n",
    "# # Same thing, done in a different way\n",
    "# pythia.add_sae(sae)\n",
    "# utils.test_prompt(prompt, answer, pythia)\n",
    "# pythia.reset_saes()  # Remember to always do this!\n",
    "\n",
    "# Using `run_with_saes` method in place of standard forward pass\n",
    "logits = pythia(prompt, return_type=\"logits\")\n",
    "logits_sae = pythia.run_with_saes(prompt, saes=[sae], return_type=\"logits\")\n",
    "answer_token_id = pythia.to_single_token(answer)\n",
    "\n",
    "# Getting model's prediction\n",
    "top_prob, token_id_prediction = logits[0, -1].softmax(-1).max(-1)\n",
    "top_prob_sae, token_id_prediction_sae = logits_sae[0, -1].softmax(-1).max(-1)\n",
    "\n",
    "print(f\"\"\"Standard model: top prediction = {pythia.to_string(token_id_prediction)!r}, prob = {top_prob.item():.2%}\n",
    "SAE reconstruction: top prediction = {pythia.to_string(token_id_prediction_sae)!r}, prob = {top_prob_sae.item():.2%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e48502-f7ec-48e4-bd68-3ba52b2306b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial P shape: torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "# %% Training Setup\n",
    "\n",
    "# Let's create tracking variables for our diagnostics\n",
    "training_stats = {\n",
    "    'loss': [],\n",
    "    'feature_loss': [],\n",
    "    'reg_loss': [],\n",
    "    'target_activation': [],\n",
    "    'gradient_norm': [],\n",
    "    'embedding_distance': [],\n",
    "    'similarity_top': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "length = 4\n",
    "d_model = pythia.cfg.d_model\n",
    "\n",
    "# Reset our parameter for a fresh start\n",
    "# Use a different initialization strategy - start closer to actual tokens\n",
    "noise_scale = 0.1  # Smaller noise\n",
    "P = torch.nn.Parameter(\n",
    "    # Start from random token embeddings instead of mean embedding\n",
    "    pythia.W_E[torch.randint(0, pythia.cfg.d_vocab, (length,))].clone() + \n",
    "    torch.randn(length, d_model, device=device) * noise_scale,\n",
    "    requires_grad=True\n",
    ")\n",
    "\n",
    "print(f\"Initial P shape: {P.shape}\")\n",
    "\n",
    "# Try a more aggressive optimizer\n",
    "optimizer = torch.optim.AdamW([P], lr=1e-1, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=20, verbose=True\n",
    ")\n",
    "\n",
    "# Create dummy tokens for the forward pass\n",
    "dummy_tokens = torch.zeros(1, length, dtype=torch.long, device=device)\n",
    "\n",
    "# Define embedding hook\n",
    "def embed_hook(value, hook):\n",
    "    return P.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac993344-4222-479e-89cb-ce8cd53482ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features by maximum activation:\n",
      "Feature 20383: Max activation = 14.0576\n",
      "Feature 7082: Max activation = 3.9123\n",
      "Feature 16939: Max activation = 3.6901\n",
      "Feature 18192: Max activation = 3.5958\n",
      "Feature 21462: Max activation = 3.5672\n",
      "Feature 27926: Max activation = 3.2479\n",
      "Feature 16970: Max activation = 2.4913\n",
      "Feature 1932: Max activation = 2.3153\n",
      "Feature 17485: Max activation = 2.1687\n",
      "Feature 11786: Max activation = 1.9848\n",
      "\n",
      "Selected feature 20383 with max activation 14.0576\n",
      "Token that most activates feature 20383: ',\\' with activation 14.0576\n"
     ]
    }
   ],
   "source": [
    "# %% Option 1: High Activation Feature from Random Tokens\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test many random token embeddings to find responsive features\n",
    "    n_samples = 100\n",
    "    sample_tokens = torch.randint(0, pythia.cfg.d_vocab, (n_samples, length), device=device)\n",
    "    \n",
    "    # Get activations for random tokens\n",
    "    all_activations = []\n",
    "    for i in range(0, n_samples, 10):  # Process in batches\n",
    "        batch = sample_tokens[i:i+10]\n",
    "        _, cache = pythia.run_with_cache_with_saes(\n",
    "            input=batch,\n",
    "            return_type=\"logits\",\n",
    "            saes=[sae]\n",
    "        )\n",
    "        batch_acts = cache['blocks.3.hook_mlp_out.hook_sae_acts_post']\n",
    "        all_activations.append(batch_acts)\n",
    "    \n",
    "    # Combine all activations\n",
    "    combined_acts = torch.cat(all_activations, dim=0)  # [n_samples, seq_len, n_features]\n",
    "    \n",
    "    # Find features with highest max activation\n",
    "    max_activations = combined_acts.max(dim=0).values.max(dim=0).values\n",
    "    \n",
    "    # Get top 10 features with highest max activation\n",
    "    top_max_features = torch.argsort(max_activations, descending=True)[:10]\n",
    "    \n",
    "    # Print info about top features\n",
    "    print(\"\\nTop features by maximum activation:\")\n",
    "    for i, feat_idx in enumerate(top_max_features):\n",
    "        print(f\"Feature {feat_idx}: Max activation = {max_activations[feat_idx]:.4f}\")\n",
    "    \n",
    "    # Choose the feature with highest max activation\n",
    "    target_feature = top_max_features[0].item()\n",
    "    print(f\"\\nSelected feature {target_feature} with max activation {max_activations[target_feature]:.4f}\")\n",
    "    \n",
    "    # Find tokens that activate this feature strongly\n",
    "    feature_activations = combined_acts[:, :, target_feature]  # [n_samples, seq_len]\n",
    "    max_activation_indices = torch.argmax(feature_activations.view(-1))\n",
    "    sample_idx = max_activation_indices // length\n",
    "    pos_idx = max_activation_indices % length\n",
    "    \n",
    "    # Get the token that most activates this feature\n",
    "    activating_token_id = sample_tokens[sample_idx, pos_idx]\n",
    "    activating_token = pythia.to_string(activating_token_id)\n",
    "    activation_value = feature_activations[sample_idx, pos_idx]\n",
    "    \n",
    "    print(f\"Token that most activates feature {target_feature}: '{activating_token}' with activation {activation_value:.4f}\")\n",
    "    \n",
    "    # Initialize P with this token's embedding plus noise\n",
    "    P.data = pythia.W_E[activating_token_id].repeat(length, 1) + torch.randn(length, d_model, device=device) * noise_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bc7d3-dc0d-49c2-af90-1ab68cf9b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for contextual features...\n",
      "\n",
      "Analyzing prompt: 'The president of the United States'\n",
      "\n",
      "Analyzing prompt: 'Once upon a time in a galaxy'\n",
      "\n",
      "Analyzing prompt: 'The quick brown fox jumps over'\n",
      "\n",
      "Analyzing prompt: 'To be or not to be that'\n",
      "\n",
      "Analyzing prompt: 'Four score and seven years ago'\n",
      "\n",
      "Top contextual features (highest position variance):\n",
      "Feature 20383: Position variance = 26.3358\n",
      "Feature 7082: Position variance = 1.6614\n",
      "Feature 21462: Position variance = 1.6153\n",
      "Feature 18192: Position variance = 1.2300\n",
      "Feature 24661: Position variance = 0.4472\n",
      "Feature 22510: Position variance = 0.2908\n",
      "Feature 28580: Position variance = 0.2782\n",
      "Feature 2082: Position variance = 0.2656\n",
      "Feature 29131: Position variance = 0.2395\n",
      "Feature 22514: Position variance = 0.1949\n",
      "Feature 8178: Position variance = 0.1913\n",
      "Feature 26284: Position variance = 0.1718\n",
      "Feature 6884: Position variance = 0.1251\n",
      "Feature 9359: Position variance = 0.0908\n",
      "Feature 29366: Position variance = 0.0814\n",
      "Feature 27926: Position variance = 0.0798\n",
      "Feature 31872: Position variance = 0.0798\n",
      "Feature 22504: Position variance = 0.0767\n",
      "Feature 16500: Position variance = 0.0673\n",
      "Feature 7228: Position variance = 0.0669\n",
      "\n",
      "Selected contextual feature 20383 for optimization\n"
     ]
    }
   ],
   "source": [
    "# %% Option 2: Contextual Features\n",
    "\n",
    "print(\"\\nSearching for contextual features...\")\n",
    "\n",
    "# Generate diverse prompts\n",
    "test_prompts = [\n",
    "    \"The president of the United States\",\n",
    "    \"Once upon a time in a galaxy\",\n",
    "    \"The quick brown fox jumps over\",\n",
    "    \"To be or not to be that\",\n",
    "    \"Four score and seven years ago\"\n",
    "]\n",
    "\n",
    "# Get the number of features from the SAE\n",
    "n_features = sae.cfg.d_sae  # Use d_sae instead of n_components\n",
    "\n",
    "# Track feature variance across positions\n",
    "feature_position_variance = torch.zeros(n_features, device=device)\n",
    "\n",
    "# Process each prompt\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nAnalyzing prompt: '{prompt}'\")\n",
    "    _, cache = pythia.run_with_cache_with_saes(prompt, saes=[sae])\n",
    "    acts = cache['blocks.3.hook_mlp_out.hook_sae_acts_post'][0]\n",
    "    \n",
    "    # For each feature, measure how much its activation varies by position\n",
    "    for feat_idx in range(n_features):\n",
    "        # Add to running variance calculation\n",
    "        feature_position_variance[feat_idx] += acts[:, feat_idx].var()\n",
    "\n",
    "# Normalize by number of prompts\n",
    "feature_position_variance /= len(test_prompts)\n",
    "\n",
    "# Get top contextual features (highest position variance)\n",
    "top_contextual_features = torch.argsort(feature_position_variance, descending=True)[:20]\n",
    "\n",
    "print(\"\\nTop contextual features (highest position variance):\")\n",
    "for i, feat_idx in enumerate(top_contextual_features):\n",
    "    print(f\"Feature {feat_idx}: Position variance = {feature_position_variance[feat_idx]:.4f}\")\n",
    "\n",
    "# Choose a contextual feature for optimization\n",
    "contextual_feature = top_contextual_features[0].item()\n",
    "print(f\"\\nSelected contextual feature {contextual_feature} for optimization\")\n",
    "\n",
    "# Now you can set target_feature = contextual_feature in your optimization\n",
    "\n",
    "target_feature = contextual_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f39790-869f-4586-96bb-59100e65ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for feature combinations...\n",
      "\n",
      "Features most correlated with feature 20383:\n",
      "Feature 21123: Correlation = nan\n",
      "Feature 21122: Correlation = nan\n",
      "Feature 21120: Correlation = nan\n",
      "Feature 21119: Correlation = nan\n",
      "Feature 21116: Correlation = nan\n"
     ]
    }
   ],
   "source": [
    "# %% Option 3: Co-Activated Features\n",
    "\n",
    "print(\"\\nSearching for feature combinations...\")\n",
    "\n",
    "# Generate many random sequences\n",
    "n_samples = 50\n",
    "sample_tokens = torch.randint(0, pythia.cfg.d_vocab, (n_samples, length), device=device)\n",
    "\n",
    "# Get activations for all samples\n",
    "all_acts = []\n",
    "for i in range(0, n_samples, 10):\n",
    "    batch = sample_tokens[i:i+10]\n",
    "    _, cache = pythia.run_with_cache_with_saes(\n",
    "        input=batch,\n",
    "        return_type=\"logits\",\n",
    "        saes=[sae]\n",
    "    )\n",
    "    batch_acts = cache['blocks.3.hook_mlp_out.hook_sae_acts_post']\n",
    "    all_acts.append(batch_acts)\n",
    "\n",
    "# Combine activations\n",
    "combined_acts = torch.cat(all_acts, dim=0)  # [n_samples, seq_len, n_features]\n",
    "\n",
    "# Get the number of features from the SAE\n",
    "n_features = sae.cfg.d_sae  # Use d_sae instead of n_components\n",
    "\n",
    "# Reshape to [n_samples*seq_len, n_features]\n",
    "reshaped_acts = combined_acts.reshape(-1, n_features)\n",
    "\n",
    "# Calculate correlation matrix between features\n",
    "feature_corr = torch.corrcoef(reshaped_acts.T)\n",
    "\n",
    "# Find features that correlate strongly with your target feature\n",
    "target_correlations = feature_corr[target_feature]\n",
    "top_correlated = torch.argsort(target_correlations.abs(), descending=True)[1:6]  # Skip self-correlation\n",
    "\n",
    "print(f\"\\nFeatures most correlated with feature {target_feature}:\")\n",
    "for feat_idx in top_correlated:\n",
    "    corr = target_correlations[feat_idx].item()\n",
    "    print(f\"Feature {feat_idx}: Correlation = {corr:.4f}\")\n",
    "\n",
    "# You could then optimize for a weighted combination of these features\n",
    "\n",
    "target_feature = top_correlated[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6fc6a-6a3b-4e18-8506-45a88b038d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial activation for feature 21123: 0.0000\n",
      "Initial top token similarity: 0.2836\n",
      "\n",
      "Initial similar tokens:\n",
      "Position 0: ,\\ (0.267)\n",
      "Position 1: ,\\ (0.318)\n",
      "Position 2: ,\\ (0.271)\n",
      "Position 3: ,\\ (0.279)\n",
      "\n",
      "Step 0\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0045\n",
      "Total loss: 0.0088\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.4435\n",
      "\n",
      "Step 20\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0006\n",
      "Total loss: 0.0655\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9415\n",
      "\n",
      "Step 40\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0735\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9845\n",
      "\n",
      "Step 60\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0003\n",
      "Total loss: 0.0727\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9914\n",
      "\n",
      "Step 80\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0739\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9938\n",
      "\n",
      "Step 100\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0743\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9920\n",
      "\n",
      "Step 120\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0741\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9946\n",
      "\n",
      "Step 140\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0001\n",
      "Total loss: 0.0744\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9934\n",
      "\n",
      "Step 160\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0003\n",
      "Total loss: 0.0730\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9860\n",
      "\n",
      "Step 180\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0743\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9944\n",
      "\n",
      "Step 200\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0002\n",
      "Total loss: 0.0740\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9941\n",
      "\n",
      "Step 220\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0001\n",
      "Total loss: 0.0744\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9935\n",
      "\n",
      "Step 240\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0001\n",
      "Total loss: 0.0747\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9966\n",
      "\n",
      "Step 260\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0001\n",
      "Total loss: 0.0746\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9973\n",
      "\n",
      "Step 280\n",
      "Target feature 21123 values: tensor([0., 0., 0., 0.])\n",
      "Feature loss: -0.0000\n",
      "Reg loss: 0.0001\n",
      "Total loss: 0.0745\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9980\n",
      "Current tokens: ,\\ ,\\ ,\\ ,\\\n",
      "Top similarity: 0.9972\n"
     ]
    }
   ],
   "source": [
    "# %% Training Loop\n",
    "\n",
    "# Track initial similarity and activation\n",
    "with torch.no_grad():\n",
    "    # Get initial token similarity\n",
    "    learned_embeds = P\n",
    "    vocab_embeds = pythia.W_E\n",
    "    similarity = torch.nn.functional.normalize(learned_embeds, dim=-1) @ \\\n",
    "                torch.nn.functional.normalize(vocab_embeds, dim=-1).T\n",
    "    initial_top_sim = similarity.max(dim=-1).values.mean().item()\n",
    "    training_stats['similarity_top'].append(initial_top_sim)\n",
    "    \n",
    "    # Get initial activation\n",
    "    with pythia.hooks(fwd_hooks=[('hook_embed', embed_hook)]):\n",
    "        _, cache = pythia.run_with_cache_with_saes(\n",
    "            input=dummy_tokens,\n",
    "            return_type=\"logits\",\n",
    "            saes=[sae]\n",
    "        )\n",
    "    initial_activation = cache['blocks.3.hook_mlp_out.hook_sae_acts_post'][0, :, target_feature].max().item()\n",
    "    print(f\"Initial activation for feature {target_feature}: {initial_activation:.4f}\")\n",
    "    print(f\"Initial top token similarity: {initial_top_sim:.4f}\")\n",
    "\n",
    "# Adjust optimization parameters\n",
    "lambda_reg = 1e-3  # Stronger regularization to keep embeddings realistic\n",
    "max_steps = 300\n",
    "\n",
    "# Create a function to get the most similar token for each position\n",
    "def get_similar_tokens(embeddings, top_k=5):\n",
    "    with torch.no_grad():\n",
    "        similarity = torch.nn.functional.normalize(embeddings, dim=-1) @ \\\n",
    "                    torch.nn.functional.normalize(vocab_embeds, dim=-1).T\n",
    "        top_tokens = similarity.topk(top_k, dim=-1)\n",
    "        \n",
    "        result = []\n",
    "        for pos in range(length):\n",
    "            tokens = [pythia.to_string(idx) for idx in top_tokens.indices[pos]]\n",
    "            scores = top_tokens.values[pos]\n",
    "            result.append((tokens, scores))\n",
    "        return result\n",
    "\n",
    "# Print initial similar tokens\n",
    "initial_tokens = get_similar_tokens(P)\n",
    "print(\"\\nInitial similar tokens:\")\n",
    "for pos, (tokens, scores) in enumerate(initial_tokens):\n",
    "    print(f\"Position {pos}: {tokens[0]} ({scores[0]:.3f})\")\n",
    "\n",
    "for step in range(max_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with pythia.hooks(fwd_hooks=[('hook_embed', embed_hook)]):\n",
    "        outputs = pythia.run_with_cache_with_saes(\n",
    "            input=dummy_tokens,\n",
    "            return_type=\"logits\",\n",
    "            saes=[sae]\n",
    "        )\n",
    "    \n",
    "    _, cache = outputs\n",
    "    sae_acts = cache['blocks.3.hook_mlp_out.hook_sae_acts_post'][0]\n",
    "    \n",
    "    # Extract target feature activation - use max activation\n",
    "    target_activation = sae_acts[:, target_feature].max()\n",
    "    \n",
    "    # Simplified loss function - focus directly on maximizing the feature\n",
    "    loss_feature = -target_activation  # No scaling needed\n",
    "    \n",
    "    # Regularization to keep embeddings close to real token embeddings\n",
    "    # Find closest token embedding for each position\n",
    "    with torch.no_grad():\n",
    "        similarity = torch.nn.functional.normalize(P, dim=-1) @ \\\n",
    "                    torch.nn.functional.normalize(vocab_embeds, dim=-1).T\n",
    "        closest_tokens = similarity.max(dim=1).indices\n",
    "        closest_embeddings = vocab_embeds[closest_tokens]\n",
    "    \n",
    "    # Regularize towards closest token embeddings\n",
    "    embedding_diff = P - closest_embeddings\n",
    "    embedding_dist = torch.norm(embedding_diff, p='fro')\n",
    "    loss_reg = lambda_reg * embedding_dist\n",
    "    \n",
    "    # Add diversity penalty to encourage different tokens\n",
    "    token_diversity_penalty = 0.0\n",
    "    with torch.no_grad():\n",
    "        # Calculate similarity between positions\n",
    "        position_similarity = torch.zeros(length, length, device=device)\n",
    "        for i in range(length):\n",
    "            for j in range(i+1, length):\n",
    "                sim = torch.nn.functional.cosine_similarity(P[i:i+1], P[j:j+1], dim=1)\n",
    "                position_similarity[i,j] = sim\n",
    "                position_similarity[j,i] = sim\n",
    "        \n",
    "        # Penalize high similarity between positions\n",
    "        token_diversity_penalty = position_similarity.mean() * 0.1\n",
    "\n",
    "    # Add to loss\n",
    "    loss = loss_feature + loss_reg + token_diversity_penalty\n",
    "    \n",
    "    # Record stats\n",
    "    training_stats['loss'].append(loss.item())\n",
    "    training_stats['feature_loss'].append(loss_feature.item())\n",
    "    training_stats['reg_loss'].append(loss_reg.item())\n",
    "    training_stats['target_activation'].append(target_activation.item())\n",
    "    training_stats['embedding_distance'].append(embedding_dist.item())\n",
    "    training_stats['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(f\"\\nStep {step}\")\n",
    "        print(f\"Target feature {target_feature} values: {sae_acts[:, target_feature]}\")\n",
    "        print(f\"Feature loss: {loss_feature.item():.4f}\")\n",
    "        print(f\"Reg loss: {loss_reg.item():.4f}\")\n",
    "        print(f\"Total loss: {loss.item():.4f}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Record gradient norm\n",
    "    grad_norm = P.grad.norm().item()\n",
    "    training_stats['gradient_norm'].append(grad_norm)\n",
    "    \n",
    "    # Gradient clipping with higher threshold\n",
    "    torch.nn.utils.clip_grad_norm_([P], max_norm=10.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update learning rate less frequently\n",
    "    if step % 10 == 0:\n",
    "        scheduler.step(loss)\n",
    "    \n",
    "    # Check similarity periodically\n",
    "    if step % 20 == 0 or step == max_steps - 1:\n",
    "        with torch.no_grad():\n",
    "            similarity = torch.nn.functional.normalize(P, dim=-1) @ \\\n",
    "                        torch.nn.functional.normalize(vocab_embeds, dim=-1).T\n",
    "            top_sim = similarity.max(dim=1).values.mean().item()\n",
    "            training_stats['similarity_top'].append(top_sim)\n",
    "            \n",
    "            # Print current similar tokens\n",
    "            similar_tokens = get_similar_tokens(P, top_k=1)\n",
    "            tokens_str = \" \".join([t[0][0] for t in similar_tokens])\n",
    "            print(f\"Current tokens: {tokens_str}\")\n",
    "            print(f\"Top similarity: {top_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e958b3c-a582-48c8-851a-45be2ba92a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Total Loss",
         "type": "scatter",
         "xaxis": "x",
         "y": [
          0.008783862926065922,
          0.01805374026298523,
          0.029517551884055138,
          0.025565030053257942,
          0.024073360487818718,
          0.029742520302534103,
          0.03842896595597267,
          0.03946107625961304,
          0.04195046424865723,
          0.04542427137494087,
          0.04679295793175697,
          0.05000341683626175,
          0.05322854965925217,
          0.05495496466755867,
          0.058530811220407486,
          0.06015449017286301,
          0.05938815698027611,
          0.060799580067396164,
          0.06376595795154572,
          0.06569875776767731,
          0.06549808382987976,
          0.0670306384563446,
          0.0676448792219162,
          0.06756323575973511,
          0.06987086683511734,
          0.06996973603963852,
          0.06941744685173035,
          0.0713881254196167,
          0.07073987275362015,
          0.07173370569944382,
          0.07196468114852905,
          0.07201007008552551,
          0.07283510267734528,
          0.072427898645401,
          0.07331355661153793,
          0.07271575927734375,
          0.0736139789223671,
          0.07266789674758911,
          0.0736103430390358,
          0.07267557829618454,
          0.07346400618553162,
          0.07296054810285568,
          0.07349994033575058,
          0.0733700543642044,
          0.07360056787729263,
          0.07359983772039413,
          0.07387489080429077,
          0.07365676015615463,
          0.07384677231311798,
          0.07395242899656296,
          0.0740111842751503,
          0.07403234392404556,
          0.07400331646203995,
          0.07411012798547745,
          0.07406702637672424,
          0.07427978515625,
          0.07381513714790344,
          0.0744672641158104,
          0.0736054852604866,
          0.07459255307912827,
          0.07267021387815475,
          0.07394734770059586,
          0.07272257655858994,
          0.07299745827913284,
          0.07378602027893066,
          0.07290766388177872,
          0.07372378557920456,
          0.0731508880853653,
          0.07338523864746094,
          0.07388953119516373,
          0.07318499684333801,
          0.07395039498806,
          0.07323317229747772,
          0.07360270619392395,
          0.07380925863981247,
          0.073621965944767,
          0.07406899333000183,
          0.0738106295466423,
          0.0739547461271286,
          0.07414157688617706,
          0.07392184436321259,
          0.07421072572469711,
          0.07369382679462433,
          0.07413936406373978,
          0.07397443801164627,
          0.07427211850881577,
          0.07381700724363327,
          0.07438983768224716,
          0.07355187088251114,
          0.07441417872905731,
          0.07360813766717911,
          0.07423288375139236,
          0.07379452884197235,
          0.07415174692869186,
          0.07399945706129074,
          0.07421635091304779,
          0.07408876717090607,
          0.0740896537899971,
          0.0740802139043808,
          0.07405270636081696,
          0.07425972819328308,
          0.07400178164243698,
          0.07428137212991714,
          0.07407724112272263,
          0.07407278567552567,
          0.07432621717453003,
          0.07379789650440216,
          0.0745047926902771,
          0.07341451197862625,
          0.07450015842914581,
          0.0733083188533783,
          0.07405605912208557,
          0.0737321674823761,
          0.07392984628677368,
          0.07408628612756729,
          0.0741019919514656,
          0.07417545467615128,
          0.07421158254146576,
          0.07415281981229782,
          0.07421866059303284,
          0.07410518825054169,
          0.07434982806444168,
          0.0740450844168663,
          0.07440987974405289,
          0.07395767420530319,
          0.07441207021474838,
          0.07400260120630264,
          0.07433942705392838,
          0.07410181313753128,
          0.07424288243055344,
          0.07435397058725357,
          0.07415217906236649,
          0.0743686854839325,
          0.07412422448396683,
          0.07439004629850388,
          0.07412781566381454,
          0.074379101395607,
          0.07405811548233032,
          0.07443305850028992,
          0.07399259507656097,
          0.07443521916866302,
          0.07417082041501999,
          0.07431142032146454,
          0.0742940828204155,
          0.07428810745477676,
          0.07433437556028366,
          0.07422442734241486,
          0.07429735362529755,
          0.07423108071088791,
          0.074351467192173,
          0.07433373481035233,
          0.07431375980377197,
          0.07444076985120773,
          0.07409687340259552,
          0.07461156696081161,
          0.07369709759950638,
          0.07477367669343948,
          0.07283193618059158,
          0.07424501329660416,
          0.07244537770748138,
          0.07300026714801788,
          0.07325063645839691,
          0.07361658662557602,
          0.07323801517486572,
          0.07393275946378708,
          0.07328789681196213,
          0.07381640374660492,
          0.0735044777393341,
          0.07391121983528137,
          0.07368411868810654,
          0.07404958456754684,
          0.07387522608041763,
          0.07416593283414841,
          0.07408704608678818,
          0.07423997670412064,
          0.07425817847251892,
          0.07430067658424377,
          0.07427656650543213,
          0.07413983345031738,
          0.0742538645863533,
          0.07425945997238159,
          0.07432571053504944,
          0.07417004555463791,
          0.07432707399129868,
          0.07428327947854996,
          0.07422415912151337,
          0.07429127395153046,
          0.07410135865211487,
          0.07445626705884933,
          0.07393068820238113,
          0.07453151047229767,
          0.07372087985277176,
          0.07453508675098419,
          0.07370545715093613,
          0.07430695742368698,
          0.07419885694980621,
          0.07400945574045181,
          0.07454018294811249,
          0.07389670610427856,
          0.07447189837694168,
          0.07404163479804993,
          0.0742575153708458,
          0.07432080805301666,
          0.0742240622639656,
          0.07427259534597397,
          0.07421145588159561,
          0.07429680228233337,
          0.07432729005813599,
          0.07416515052318573,
          0.074361652135849,
          0.07422003149986267,
          0.07420925796031952,
          0.0748576894402504,
          0.07399407029151917,
          0.07464975118637085,
          0.07386944442987442,
          0.07434023171663284,
          0.07399595528841019,
          0.07441211491823196,
          0.07408545911312103,
          0.0744125172495842,
          0.07420211285352707,
          0.07447347044944763,
          0.07430632412433624,
          0.07452770322561264,
          0.07441528886556625,
          0.07460492104291916,
          0.07450157403945923,
          0.07468286901712418,
          0.07453213632106781,
          0.07473613321781158,
          0.07456959038972855,
          0.0747046023607254,
          0.07458340376615524,
          0.0746326670050621,
          0.07463142275810242,
          0.0746360719203949,
          0.07465464621782303,
          0.07459840923547745,
          0.07464522123336792,
          0.07465392351150513,
          0.07461407780647278,
          0.07468455284833908,
          0.07457149028778076,
          0.074711374938488,
          0.07457402348518372,
          0.07468941062688828,
          0.0746549740433693,
          0.07463620603084564,
          0.07474838197231293,
          0.07444575428962708,
          0.074823759496212,
          0.07435431331396103,
          0.07480791956186295,
          0.0743698924779892,
          0.07473210990428925,
          0.07451632618904114,
          0.07467620074748993,
          0.07462817430496216,
          0.07470685988664627,
          0.07462482154369354,
          0.07468657195568085,
          0.07463440299034119,
          0.07467122375965118,
          0.07466156035661697,
          0.07462992519140244,
          0.07472572475671768,
          0.07454657554626465,
          0.07476439327001572,
          0.07451942563056946,
          0.07473056763410568,
          0.07459802180528641,
          0.0746946707367897,
          0.07466436177492142,
          0.07467497885227203,
          0.07470434904098511,
          0.07466328889131546,
          0.07467450946569443,
          0.0746522769331932,
          0.07472897320985794,
          0.07453678548336029,
          0.07478582859039307,
          0.07448820024728775,
          0.0748172476887703,
          0.07439874112606049,
          0.07477981597185135,
          0.07456624507904053,
          0.074691042304039,
          0.07472018897533417,
          0.07460147887468338,
          0.07473160326480865,
          0.07463586330413818,
          0.0746750757098198,
          0.0747232735157013,
          0.07456286251544952,
          0.07482467591762543,
          0.07442359626293182,
          0.074812151491642,
          0.07443881779909134,
          0.0747220516204834
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Feature Loss",
         "type": "scatter",
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Regularization Loss",
         "type": "scatter",
         "xaxis": "x",
         "y": [
          0.004481925629079342,
          0.0028458270244300365,
          0.0018487684428691864,
          0.0021204764489084482,
          0.002270916709676385,
          0.0018212426220998168,
          0.0013437159359455109,
          0.0013553634053096175,
          0.0013284885790199041,
          0.0011874985648319125,
          0.001109414966776967,
          0.0010354636469855905,
          0.0009656529291532934,
          0.0009018696146085858,
          0.0007802617037668824,
          0.0007357138674706221,
          0.0007531117298640311,
          0.0007011574925854802,
          0.0006146222003735602,
          0.000563759240321815,
          0.0005640215240418911,
          0.0005064369179308414,
          0.0004874727164860815,
          0.0004848297103308141,
          0.00040496568544767797,
          0.00039358160574920475,
          0.00040613560122437775,
          0.00033573407563380897,
          0.0003586838720366359,
          0.00031917079468257725,
          0.00030252899159677327,
          0.0003049184160772711,
          0.0002556226681917906,
          0.00028357424889691174,
          0.00022719924163538963,
          0.0002683532948140055,
          0.00020976302039343864,
          0.00027013011276721954,
          0.00021031813230365515,
          0.00026426048134453595,
          0.0002185991033911705,
          0.0002514813095331192,
          0.00021874748927075416,
          0.00022703550348524004,
          0.00020962388953194022,
          0.0002099928678944707,
          0.00018984476628247648,
          0.0002051856426987797,
          0.00018863799050450325,
          0.00018518802244216204,
          0.00017996628594119102,
          0.00017796778411138803,
          0.00017846153059508651,
          0.00016908184625208378,
          0.0001730174117255956,
          0.00015472224913537502,
          0.0001957660133484751,
          0.00013539212523028255,
          0.0002107706677634269,
          0.0001195787699543871,
          0.00026832905132323503,
          0.0001859318872448057,
          0.0002653923293109983,
          0.00025313490186817944,
          0.00019452712149359286,
          0.0002563497400842607,
          0.00020323172793723643,
          0.0002386400883551687,
          0.0002279686159454286,
          0.00018604297656565905,
          0.00023877470812294632,
          0.00018151226686313748,
          0.0002339091442991048,
          0.00020967936143279076,
          0.00019125445396639407,
          0.000209462086786516,
          0.00017348959227092564,
          0.0001936602930072695,
          0.00018138258019462228,
          0.00016328017227351665,
          0.0001865121303126216,
          0.00015860318671911955,
          0.00019889225950464606,
          0.00017161585856229067,
          0.00018460840510670096,
          0.00015611150593031198,
          0.00019415437418501824,
          0.00014350922720041126,
          0.00021195932640694082,
          0.00014121780986897647,
          0.00021125812781974673,
          0.0001572522596688941,
          0.0001949412253452465,
          0.00016660256369505078,
          0.00017748301615938544,
          0.00016144791152328253,
          0.000173996711964719,
          0.00017135941016022116,
          0.0001699476852081716,
          0.0001729543728288263,
          0.00015768836601637304,
          0.00018045247998088598,
          0.0001525141706224531,
          0.0001691035577096045,
          0.0001695696118986234,
          0.00014824261597823352,
          0.00019354575488250703,
          0.00012767474981956184,
          0.0002180523588322103,
          0.0001314267865382135,
          0.000226734351599589,
          0.00017419864889234304,
          0.00019640923710539937,
          0.00018452071526553482,
          0.00017027639842126518,
          0.00016931550635490566,
          0.00016160382074303925,
          0.00015768046432640404,
          0.0001663198636379093,
          0.00016061171481851488,
          0.00017191842198371887,
          0.0001475986500736326,
          0.0001760449231369421,
          0.00014250849199015647,
          0.00018387625459581614,
          0.00014003181422594935,
          0.00017827986448537558,
          0.00014521629782393575,
          0.00016895374574232846,
          0.00015662764781154692,
          0.00014538521645590663,
          0.0001637363457120955,
          0.00014792874571867287,
          0.00016871746629476547,
          0.00014300893235486,
          0.00016858780873008072,
          0.00014324250514619052,
          0.00017521387781016529,
          0.00013693844084627926,
          0.00017779343761503696,
          0.00013837018923368305,
          0.0001631785708013922,
          0.00015046278713271022,
          0.00015325505228247494,
          0.00015285270637832582,
          0.00014612187806051224,
          0.00015866510511841625,
          0.0001505114632891491,
          0.00015851865464355797,
          0.00014553582877852023,
          0.00015064308536238968,
          0.00015534873818978667,
          0.00013794719416182488,
          0.00017445166304241866,
          0.00011751371494028717,
          0.00020505356951616704,
          0.0000948485903791152,
          0.00025962083600461483,
          0.000156720430823043,
          0.00028783243033103645,
          0.000250546756433323,
          0.0002381230442551896,
          0.00020629953360185027,
          0.00023864139802753925,
          0.00018435969832353294,
          0.00023160057025961578,
          0.00019108715059701353,
          0.0002163449244108051,
          0.00018460123101249337,
          0.0002012829208979383,
          0.00017246772767975926,
          0.0001871960994321853,
          0.00016328325727954507,
          0.0001688014017418027,
          0.0001571863394929096,
          0.00015288252325262874,
          0.00015260044892784208,
          0.00015065597835928202,
          0.0001666500756982714,
          0.00015309620357584208,
          0.0001567109429743141,
          0.0001500115031376481,
          0.0001648004981689155,
          0.00014989179908297956,
          0.0001564153644721955,
          0.0001594069181010127,
          0.0001501189690316096,
          0.00017142682918347418,
          0.00013570382725447416,
          0.00018490459478925914,
          0.0001271860091947019,
          0.00020473499898798764,
          0.00012574177526403219,
          0.00020364265947137028,
          0.00015193190483842045,
          0.00016280036652460694,
          0.00017713304259814322,
          0.0001247154432348907,
          0.00018705685215536505,
          0.00013472477439790964,
          0.00017615800607018173,
          0.00015335524221882224,
          0.00015053489187266678,
          0.00016008420789148659,
          0.0001562614634167403,
          0.00016265657905023545,
          0.00015446054749190807,
          0.00014940231631044298,
          0.00016343047900591046,
          0.0001471510622650385,
          0.00016154609329532832,
          0.0001589845196576789,
          0.00007629867468494922,
          0.00017983424186240882,
          0.00011185900075361133,
          0.00019048342073801905,
          0.00014737404126208276,
          0.00017992350331041962,
          0.00013883999781683087,
          0.00017296809528488666,
          0.00013896793825551867,
          0.00016132683958858252,
          0.00013178489462006837,
          0.00015147805970627815,
          0.0001257255207747221,
          0.00013791506353300065,
          0.00011784718662966043,
          0.00012741575483232737,
          0.0001063992822309956,
          0.00012334756320342422,
          0.00009981725452234969,
          0.00012100805906811729,
          0.00010212464985670522,
          0.00011917862866539508,
          0.00011146101314807311,
          0.00011234148405492306,
          0.00011383972741896287,
          0.00010988173016812652,
          0.00011600572906900197,
          0.00011128157348139212,
          0.00010978974751196802,
          0.00011658420407911763,
          0.00010574354382697493,
          0.00012187378160888329,
          0.00010180751996813342,
          0.00011953315697610378,
          0.0001065159885911271,
          0.00011280689795967191,
          0.0001141964239650406,
          0.00009644929377827793,
          0.000134905320010148,
          0.00008353478187927976,
          0.00014629034558311105,
          0.00008505644655087963,
          0.00014243272016756237,
          0.00009936089190887287,
          0.0001264220627490431,
          0.00010777756688185036,
          0.00011287702363915741,
          0.00010366646165493876,
          0.00011550404451554641,
          0.00010442369239171967,
          0.00011338850163156167,
          0.00010942365042865276,
          0.00011058386735385284,
          0.000113563502964098,
          0.00010111089068232104,
          0.00012374331708997488,
          0.00009369711187900975,
          0.00012775017239619046,
          0.00009889929788187146,
          0.00011832967720692977,
          0.00010600397945381701,
          0.00011031505709979683,
          0.0001090809892048128,
          0.00010673189535737038,
          0.00011058925883844495,
          0.00010697584366425872,
          0.00011074247595388442,
          0.00009835307719185948,
          0.0001240299316123128,
          0.00008971985516836867,
          0.0001316358830081299,
          0.00008446400170214474,
          0.00014113842917140573,
          0.00009153889550361782,
          0.00012312324543017894,
          0.00010605921124806628,
          0.00009995502477977425,
          0.00011669301602523774,
          0.00009795585356187075,
          0.00011239753803238273,
          0.00010743662278400734,
          0.0000999116018647328,
          0.00012206322571728379,
          0.00008457367948722094,
          0.00013933713489677757,
          0.00008432778849964961,
          0.00013467554526869208,
          0.00010200733231613412
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Target Activation",
         "type": "scatter",
         "xaxis": "x2",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y2"
        },
        {
         "mode": "lines",
         "name": "Gradient Norm",
         "type": "scatter",
         "xaxis": "x3",
         "y": [
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.001000000280328095,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0009999999310821295,
          0.0010000001639127731,
          0.001000000280328095,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0009999999310821295,
          0.0009999999310821295,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000000474974513,
          0.001000000280328095,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000001639127731,
          0.0010000001639127731,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000000474974513,
          0.0010000001639127731
         ],
         "yaxis": "y3"
        },
        {
         "mode": "lines",
         "name": "Embedding Distance",
         "type": "scatter",
         "xaxis": "x4",
         "y": [
          4.4819254875183105,
          2.8458268642425537,
          1.8487683534622192,
          2.120476245880127,
          2.270916700363159,
          1.8212425708770752,
          1.3437159061431885,
          1.355363368988037,
          1.3284884691238403,
          1.1874984502792358,
          1.1094149351119995,
          1.035463571548462,
          0.9656528830528259,
          0.9018695950508118,
          0.7802616953849792,
          0.7357138395309448,
          0.753111720085144,
          0.7011574506759644,
          0.614622175693512,
          0.5637592077255249,
          0.5640214681625366,
          0.5064368844032288,
          0.48747268319129944,
          0.48482969403266907,
          0.40496566891670227,
          0.3935815989971161,
          0.40613558888435364,
          0.3357340693473816,
          0.35868385434150696,
          0.3191707730293274,
          0.302528977394104,
          0.30491840839385986,
          0.25562265515327454,
          0.2835742235183716,
          0.2271992266178131,
          0.26835328340530396,
          0.20976300537586212,
          0.27013009786605835,
          0.21031811833381653,
          0.264260470867157,
          0.2185990959405899,
          0.251481294631958,
          0.21874748170375824,
          0.2270354926586151,
          0.20962387323379517,
          0.20999285578727722,
          0.1898447573184967,
          0.2051856368780136,
          0.18863798677921295,
          0.18518801033496857,
          0.1799662709236145,
          0.17796777188777924,
          0.17846152186393738,
          0.16908183693885803,
          0.17301739752292633,
          0.15472224354743958,
          0.19576600193977356,
          0.13539211452007294,
          0.2107706516981125,
          0.1195787638425827,
          0.26832902431488037,
          0.18593187630176544,
          0.2653923034667969,
          0.2531348764896393,
          0.19452711939811707,
          0.25634974241256714,
          0.20323172211647034,
          0.23864006996154785,
          0.22796860337257385,
          0.18604296445846558,
          0.23877470195293427,
          0.181512251496315,
          0.23390913009643555,
          0.20967935025691986,
          0.19125445187091827,
          0.20946207642555237,
          0.17348958551883698,
          0.19366028904914856,
          0.18138256669044495,
          0.1632801592350006,
          0.18651212751865387,
          0.15860317647457123,
          0.1988922506570816,
          0.1716158539056778,
          0.18460839986801147,
          0.15611149370670319,
          0.19415436685085297,
          0.14350922405719757,
          0.21195931732654572,
          0.14121779799461365,
          0.21125811338424683,
          0.1572522521018982,
          0.1949412226676941,
          0.16660255193710327,
          0.17748300731182098,
          0.1614478975534439,
          0.173996701836586,
          0.17135940492153168,
          0.16994768381118774,
          0.17295436561107635,
          0.15768836438655853,
          0.18045246601104736,
          0.15251415967941284,
          0.16910354793071747,
          0.16956959664821625,
          0.14824260771274567,
          0.19354574382305145,
          0.12767474353313446,
          0.21805234253406525,
          0.13142678141593933,
          0.22673434019088745,
          0.17419864237308502,
          0.1964092254638672,
          0.18452070653438568,
          0.17027638852596283,
          0.16931550204753876,
          0.16160380840301514,
          0.1576804518699646,
          0.1663198620080948,
          0.16061170399188995,
          0.17191840708255768,
          0.14759863913059235,
          0.17604491114616394,
          0.14250849187374115,
          0.18387624621391296,
          0.1400318145751953,
          0.17827986180782318,
          0.14521628618240356,
          0.16895373165607452,
          0.15662764012813568,
          0.14538520574569702,
          0.16373634338378906,
          0.14792874455451965,
          0.16871745884418488,
          0.14300893247127533,
          0.1685878038406372,
          0.1432424932718277,
          0.17521387338638306,
          0.1369384378194809,
          0.17779342830181122,
          0.13837018609046936,
          0.16317856311798096,
          0.1504627764225006,
          0.15325504541397095,
          0.15285269916057587,
          0.14612187445163727,
          0.15866509079933167,
          0.1505114585161209,
          0.15851864218711853,
          0.14553582668304443,
          0.15064308047294617,
          0.1553487330675125,
          0.1379471868276596,
          0.17445164918899536,
          0.11751370877027512,
          0.20505355298519135,
          0.09484858810901642,
          0.2596208155155182,
          0.15672042965888977,
          0.2878324091434479,
          0.25054675340652466,
          0.23812302947044373,
          0.2062995284795761,
          0.2386413812637329,
          0.18435968458652496,
          0.2316005527973175,
          0.19108714163303375,
          0.2163449078798294,
          0.18460121750831604,
          0.20128291845321655,
          0.17246772348880768,
          0.18719609081745148,
          0.16328324377536774,
          0.16880139708518982,
          0.1571863293647766,
          0.15288251638412476,
          0.15260043740272522,
          0.15065596997737885,
          0.16665007174015045,
          0.15309619903564453,
          0.1567109376192093,
          0.15001149475574493,
          0.1648004949092865,
          0.14989179372787476,
          0.15641535818576813,
          0.15940691530704498,
          0.15011896193027496,
          0.17142681777477264,
          0.13570381700992584,
          0.18490459024906158,
          0.12718600034713745,
          0.20473499596118927,
          0.12574176490306854,
          0.20364265143871307,
          0.15193189680576324,
          0.1628003567457199,
          0.17713303864002228,
          0.12471543252468109,
          0.18705683946609497,
          0.13472476601600647,
          0.17615799605846405,
          0.15335524082183838,
          0.15053488314151764,
          0.16008420288562775,
          0.15626145899295807,
          0.16265657544136047,
          0.15446053445339203,
          0.14940230548381805,
          0.16343046724796295,
          0.14715105295181274,
          0.16154608130455017,
          0.15898451209068298,
          0.07629866898059845,
          0.17983423173427582,
          0.11185899376869202,
          0.19048340618610382,
          0.14737403392791748,
          0.17992348968982697,
          0.138839989900589,
          0.1729680895805359,
          0.13896793127059937,
          0.1613268256187439,
          0.13178488612174988,
          0.15147805213928223,
          0.12572550773620605,
          0.13791505992412567,
          0.11784718185663223,
          0.1274157464504242,
          0.10639927536249161,
          0.12334755808115005,
          0.09981724619865417,
          0.12100805342197418,
          0.1021246463060379,
          0.11917862296104431,
          0.11146100610494614,
          0.11234147846698761,
          0.11383972316980362,
          0.10988172143697739,
          0.11600572615861893,
          0.11128156632184982,
          0.10978974401950836,
          0.11658419668674469,
          0.10574354231357574,
          0.12187377363443375,
          0.10180751234292984,
          0.11953315138816833,
          0.10651598125696182,
          0.11280689388513565,
          0.11419641971588135,
          0.09644928574562073,
          0.13490530848503113,
          0.08353477716445923,
          0.14629033207893372,
          0.08505643904209137,
          0.14243271946907043,
          0.099360890686512,
          0.12642206251621246,
          0.10777755826711655,
          0.1128770187497139,
          0.10366645455360413,
          0.11550404131412506,
          0.10442368686199188,
          0.11338849365711212,
          0.10942364484071732,
          0.11058386415243149,
          0.11356350034475327,
          0.10111088305711746,
          0.12374331057071686,
          0.09369710832834244,
          0.12775017321109772,
          0.09889928996562958,
          0.11832967400550842,
          0.10600397735834122,
          0.11031505465507507,
          0.10908098518848419,
          0.10673189163208008,
          0.11058925092220306,
          0.10697583854198456,
          0.1107424721121788,
          0.0983530730009079,
          0.12402991950511932,
          0.08971985429525375,
          0.1316358745098114,
          0.08446399867534637,
          0.14113841950893402,
          0.09153889119625092,
          0.12312324345111847,
          0.10605920851230621,
          0.09995502233505249,
          0.11669301241636276,
          0.0979558452963829,
          0.11239752918481827,
          0.10743661969900131,
          0.09991160035133362,
          0.12206321954727173,
          0.08457367867231369,
          0.13933712244033813,
          0.08432778716087341,
          0.134675532579422,
          0.10200732946395874
         ],
         "yaxis": "y4"
        },
        {
         "mode": "lines",
         "name": "Learning Rate",
         "type": "scatter",
         "xaxis": "x5",
         "y": [
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999,
          0.06999999999999999
         ],
         "yaxis": "y5"
        },
        {
         "mode": "lines+markers",
         "name": "Top Token Similarity",
         "type": "scatter",
         "x": [
          0,
          20,
          40,
          60,
          80,
          100,
          120,
          140,
          160,
          180,
          200,
          220,
          240,
          260,
          280,
          299
         ],
         "xaxis": "x6",
         "y": [
          0.28361785411834717,
          0.44353270530700684,
          0.9414608478546143,
          0.9845357537269592,
          0.9914124011993408,
          0.9937630891799927,
          0.9919825792312622,
          0.9945782423019409,
          0.9934111833572388,
          0.9859986305236816,
          0.9944478273391724,
          0.9941006898880005,
          0.9935151934623718,
          0.996620774269104,
          0.9972772598266602,
          0.9979784488677979,
          0.9972149133682251
         ],
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Loss Components",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Target Feature Activation",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Gradient Norm",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Embedding Distance from Mean",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Learning Rate",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Top Token Similarity",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 900,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Feature Optimization Training Progress"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7777777777777778,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7777777777777778,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.22222222222222224
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.22222222222222224
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Visualize Training Progress\n",
    "\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = sp.make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Loss Components', 'Target Feature Activation',\n",
    "        'Gradient Norm', 'Embedding Distance from Mean',\n",
    "        'Learning Rate', 'Top Token Similarity'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot loss components\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['loss'], mode='lines', name='Total Loss'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['feature_loss'], mode='lines', name='Feature Loss'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['reg_loss'], mode='lines', name='Regularization Loss'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot target activation\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['target_activation'], mode='lines', name='Target Activation'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot gradient norm\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['gradient_norm'], mode='lines', name='Gradient Norm'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot embedding distance\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['embedding_distance'], mode='lines', name='Embedding Distance'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Plot learning rate\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=training_stats['learning_rates'], mode='lines', name='Learning Rate'),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Plot top similarity\n",
    "steps = list(range(0, max_steps, 20)) + [max_steps-1]\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=steps, y=training_stats['similarity_top'], mode='lines+markers', name='Top Token Similarity'),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=900, width=1000, title_text=\"Feature Optimization Training Progress\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e8b4c-891b-456a-b310-1fca77dd1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== RESULTS FOR FEATURE 21123 ===\n",
      "\n",
      "Optimized sequence as tokens:\n",
      "Position 0:\n",
      "  ,\\                   (similarity: 0.997)\n",
      "  },\\                  (similarity: 0.598)\n",
      "   ,\\                  (similarity: 0.576)\n",
      "  ),\\                  (similarity: 0.484)\n",
      "  ',\\                  (similarity: 0.479)\n",
      "Position 1:\n",
      "  ,\\                   (similarity: 0.997)\n",
      "  },\\                  (similarity: 0.604)\n",
      "   ,\\                  (similarity: 0.575)\n",
      "  ),\\                  (similarity: 0.485)\n",
      "  ',\\                  (similarity: 0.479)\n",
      "Position 2:\n",
      "  ,\\                   (similarity: 0.997)\n",
      "  },\\                  (similarity: 0.600)\n",
      "   ,\\                  (similarity: 0.578)\n",
      "  ),\\                  (similarity: 0.487)\n",
      "  ',\\                  (similarity: 0.483)\n",
      "Position 3:\n",
      "  ,\\                   (similarity: 0.997)\n",
      "  },\\                  (similarity: 0.602)\n",
      "   ,\\                  (similarity: 0.577)\n",
      "  ),\\                  (similarity: 0.485)\n",
      "  ',\\                  (similarity: 0.479)\n",
      "\n",
      "Feature 21123 activation pattern:\n",
      "Position 0: 0.0000\n",
      "Position 1: 0.0000\n",
      "Position 2: 0.0000\n",
      "Position 3: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "red"
         },
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3
         ],
         "y": [
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Feature 21123 Activation Pattern"
        },
        "xaxis": {
         "title": {
          "text": "Sequence Position"
         }
        },
        "yaxis": {
         "title": {
          "text": "Activation Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other strongly activated features:\n",
      "Feature 20383: 14.0950\n",
      "Feature 18192: 3.4520\n",
      "Feature 21462: 3.1163\n",
      "Feature 7082: 2.3640\n",
      "Feature 27926: 0.5587\n",
      "Feature 5167: 0.4007\n",
      "Feature 26654: 0.3800\n",
      "Feature 9123: 0.3457\n",
      "Feature 16970: 0.3168\n",
      "Feature 31054: 0.2910\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Feature 20383",
         "type": "bar",
         "x": [
          "Pos 0",
          "Pos 1",
          "Pos 2",
          "Pos 3"
         ],
         "y": [
          14.107652,
          14.102111,
          14.099844,
          14.0703745
         ]
        },
        {
         "name": "Feature 18192",
         "type": "bar",
         "x": [
          "Pos 0",
          "Pos 1",
          "Pos 2",
          "Pos 3"
         ],
         "y": [
          3.4602365,
          3.4535384,
          3.4617434,
          3.4323702
         ]
        },
        {
         "name": "Feature 21462",
         "type": "bar",
         "x": [
          "Pos 0",
          "Pos 1",
          "Pos 2",
          "Pos 3"
         ],
         "y": [
          3.1177108,
          3.1157024,
          3.1075704,
          3.1240408
         ]
        },
        {
         "name": "Feature 7082",
         "type": "bar",
         "x": [
          "Pos 0",
          "Pos 1",
          "Pos 2",
          "Pos 3"
         ],
         "y": [
          2.3592346,
          2.3607616,
          2.361091,
          2.3750908
         ]
        },
        {
         "name": "Feature 27926",
         "type": "bar",
         "x": [
          "Pos 0",
          "Pos 1",
          "Pos 2",
          "Pos 3"
         ],
         "y": [
          0.5391558,
          0.56612784,
          0.56328636,
          0.56614894
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Activation Patterns for Top Features"
        },
        "xaxis": {
         "title": {
          "text": "Sequence Position"
         }
        },
        "yaxis": {
         "title": {
          "text": "Activation Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Analyze Results\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get activations with optimized embeddings\n",
    "    with pythia.hooks(fwd_hooks=[('hook_embed', embed_hook)]):\n",
    "        _, final_cache = pythia.run_with_cache_with_saes(\n",
    "            input=dummy_tokens,\n",
    "            return_type=\"logits\",\n",
    "            saes=[sae]\n",
    "        )\n",
    "    \n",
    "    # Extract activations\n",
    "    final_acts = final_cache['blocks.3.hook_mlp_out.hook_sae_acts_post'][0]\n",
    "    \n",
    "    # 1. Show the optimized token sequence\n",
    "    learned_embeds = P  # [length, d_model]\n",
    "    vocab_embeds = pythia.W_E  # [vocab_size, d_model]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = torch.nn.functional.normalize(learned_embeds, dim=-1) @ \\\n",
    "                torch.nn.functional.normalize(vocab_embeds, dim=-1).T\n",
    "    \n",
    "    # Get top tokens for each position\n",
    "    top_k = 5\n",
    "    top_tokens = similarity.topk(top_k, dim=-1)\n",
    "    \n",
    "    print(f\"\\n\\n=== RESULTS FOR FEATURE {target_feature} ===\")\n",
    "    print(\"\\nOptimized sequence as tokens:\")\n",
    "    for pos in range(length):\n",
    "        tokens = [pythia.to_string(idx) for idx in top_tokens.indices[pos]]\n",
    "        scores = top_tokens.values[pos]\n",
    "        print(f\"Position {pos}:\")\n",
    "        for token, score in zip(tokens, scores):\n",
    "            print(f\"  {token:20} (similarity: {score:.3f})\")\n",
    "    \n",
    "    # 2. Show feature activation pattern\n",
    "    print(f\"\\nFeature {target_feature} activation pattern:\")\n",
    "    for pos in range(length):\n",
    "        print(f\"Position {pos}: {final_acts[pos, target_feature]:.4f}\")\n",
    "    \n",
    "    # 3. Plot activation pattern\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(range(length)),\n",
    "        y=final_acts[:, target_feature].cpu().numpy(),\n",
    "        marker_color='red'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Feature {target_feature} Activation Pattern',\n",
    "        xaxis_title='Sequence Position',\n",
    "        yaxis_title='Activation Value',\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # 4. Check for other strongly activated features\n",
    "    # Get mean activation for each feature\n",
    "    mean_acts = final_acts.mean(dim=0)\n",
    "    # Get top activated features\n",
    "    top_activated = torch.argsort(mean_acts, descending=True)[:10]\n",
    "    \n",
    "    print(\"\\nOther strongly activated features:\")\n",
    "    for i, feat_idx in enumerate(top_activated):\n",
    "        if feat_idx == target_feature:\n",
    "            print(f\"Feature {feat_idx}: {mean_acts[feat_idx]:.4f} (target feature)\")\n",
    "        else:\n",
    "            print(f\"Feature {feat_idx}: {mean_acts[feat_idx]:.4f}\")\n",
    "    \n",
    "    # 5. Visualize activation pattern across all positions for top features\n",
    "    top_5_features = top_activated[:5]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for feat_idx in top_5_features:\n",
    "        feat_name = f\"Feature {feat_idx}\"\n",
    "        if feat_idx == target_feature:\n",
    "            feat_name += \" (target)\"\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=[f\"Pos {i}\" for i in range(length)],\n",
    "            y=final_acts[:, feat_idx].cpu().numpy(),\n",
    "            name=feat_name\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Activation Patterns for Top Features',\n",
    "        xaxis_title='Sequence Position',\n",
    "        yaxis_title='Activation Value',\n",
    "        barmode='group'\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
