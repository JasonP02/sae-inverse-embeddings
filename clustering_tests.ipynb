{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview & Current Questions\n",
    "This is for validating my clustering idea:\n",
    "1. Store SAE activations for all prompts\n",
    "2. Preprocess activations based on entropy and activation level (optional?)\n",
    "3. Cluster activations using UMAP and HDBSCAN\n",
    "4. Analyze clusters\n",
    "\n",
    "Some questions: \n",
    "1. How does entropy, activation preprocessing affect clustering? How does n_prompts, length, affect this step?\n",
    "2. How useful is UMAP? What are the best parameters?\n",
    "3. How does HDBSCAN perform? What are the best parameters?\n",
    "4. How does the clustering change when we use different datasets?\n",
    "5. What commonalities do clusters have? Does this vary by dataset? Hyperparameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, config, model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "import torch\n",
    "import gc\n",
    "from config import config # cfg auto updates\n",
    "\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import umap.umap_ as umap\n",
    "import plotly.graph_objects as go\n",
    "from einops import rearrange\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = HookedSAETransformer.from_pretrained(\"EleutherAI/pythia-70m-deduped\", device=device)\n",
    "sae, _, _ = SAE.from_pretrained(\n",
    "    release=\"pythia-70m-deduped-mlp-sm\",\n",
    "    sae_id=\"blocks.3.hook_mlp_out\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Activations from get_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prompts_1000']\n",
      "Loading processed data from feature_cache/processed_data_prompts_1000.pt...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def load_processed_data(filename):\n",
    "    \"\"\"Load processed data from disk.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Loading processed data from {filename}...\")\n",
    "        try:\n",
    "            data = torch.load(filename)\n",
    "            print(\"Data loaded successfully.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No cached data found at {filename}\")\n",
    "        return None\n",
    "    \n",
    "def get_cache_filename(config, n_prompts):\n",
    "    \"\"\"Generate a cache filename based on hierarchical config parameters.\"\"\"\n",
    "    # Create a unique filename based on key parameters\n",
    "    \n",
    "    params = [\n",
    "        f\"prompts_{n_prompts}\",\n",
    "    ]\n",
    "    print(params)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    cache_dir = config.get('cache_dir', 'cache')\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    return os.path.join(cache_dir, f\"processed_data_{'_'.join(params)}.pt\") \n",
    "\n",
    "# Determine whether to use cached data \n",
    "n_prompts = config['n_prompts']\n",
    "use_cached_data = config['use_cached_data']\n",
    "cache_filename = get_cache_filename(config, n_prompts)\n",
    "cached_data = load_processed_data(cache_filename)\n",
    "\n",
    "\n",
    "acts = cached_data['acts']\n",
    "prompts = cached_data.get('prompts', [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering using entropy and sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 5.78 GiB of which 72.12 MiB is free. Process 214109 has 6.15 MiB memory in use. Including non-PyTorch memory, this process has 1.73 GiB memory in use. Process 231363 has 1.17 GiB memory in use. Of the allocated memory 1.43 GiB is allocated by PyTorch, and 212.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 60\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acts[:, mask], mask\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m], entropy, sparsity, varentropy\n\u001b[0;32m---> 60\u001b[0m filtered_acts, original_indices, entropy_data, sparsity_data, varentropy_data \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m after filtering acts.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macts\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisualize_features\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame for entropy and sparsity\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 46\u001b[0m, in \u001b[0;36mfilter_features\u001b[0;34m(acts, config)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mFilter features based on entropy and sparsity.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mWe are looking at the feature behavior across prompts (we could modify this for tokens, or even for tokens within prompts)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m n_prompts, n_features \u001b[38;5;241m=\u001b[39m acts\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 46\u001b[0m entropy, sparsity, varentropy \u001b[38;5;241m=\u001b[39m \u001b[43mget_entropy_sparsity_varentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_prompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Apply filtering mask\u001b[39;00m\n\u001b[1;32m     49\u001b[0m mask \u001b[38;5;241m=\u001b[39m (entropy \u001b[38;5;241m>\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy_threshold_low\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m \\\n\u001b[1;32m     50\u001b[0m        (entropy \u001b[38;5;241m<\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy_threshold_high\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m \\\n\u001b[1;32m     51\u001b[0m        (sparsity \u001b[38;5;241m>\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity_min\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m \\\n\u001b[1;32m     52\u001b[0m        (sparsity \u001b[38;5;241m<\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity_max\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[45], line 13\u001b[0m, in \u001b[0;36mget_entropy_sparsity_varentropy\u001b[0;34m(acts, config, n_prompts)\u001b[0m\n\u001b[1;32m     11\u001b[0m entropy_per_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(probs \u001b[38;5;241m*\u001b[39m log_probs)  \u001b[38;5;66;03m# Shape: [n_prompts, n_features]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m mean_entropy \u001b[38;5;241m=\u001b[39m entropy_per_prompt\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: [n_features]\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m varentropy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43m(\u001b[49m\u001b[43mentropy_per_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean_entropy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: [n_features]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# variance of entropy is a measure of how much the entropy varies across prompts \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# i posit that this will be useful for clustering\u001b[39;00m\n\u001b[1;32m     17\u001b[0m activation_threshold \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 5.78 GiB of which 72.12 MiB is free. Process 214109 has 6.15 MiB memory in use. Including non-PyTorch memory, this process has 1.73 GiB memory in use. Process 231363 has 1.17 GiB memory in use. Of the allocated memory 1.43 GiB is allocated by PyTorch, and 212.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def get_entropy_sparsity_varentropy(acts, config, n_prompts):\n",
    "    \n",
    "    # Calculate entropy and sparsity\n",
    "    activations = acts.abs()\n",
    "    probs = activations / (activations.sum(dim=0) + 1e-10)\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=0)\n",
    "\n",
    "    # Correct varentropy calculation\n",
    "    # We want variance of entropy across prompts for each feature\n",
    "    log_probs = torch.log(probs + 1e-10)\n",
    "    entropy_per_prompt = -(probs * log_probs)  # Shape: [n_prompts, n_features]\n",
    "    mean_entropy = entropy_per_prompt.mean(dim=0)  # Shape: [n_features]\n",
    "    varentropy = torch.mean((entropy_per_prompt - mean_entropy.unsqueeze(0))**2, dim=0)  # Shape: [n_features]\n",
    "    # variance of entropy is a measure of how much the entropy varies across prompts \n",
    "    # i posit that this will be useful for clustering\n",
    "    \n",
    "    activation_threshold = config.get('activation_threshold', 0.1)\n",
    "    sparsity = (acts.abs() > activation_threshold).float().mean(dim=0)\n",
    "\n",
    "    if config['verbose']:\n",
    "        # After calculating entropy and sparsity\n",
    "        print(f\"\\nEntropy stats:\")\n",
    "        print(f\"Min: {entropy.min().item():.3f}\")\n",
    "        print(f\"Max: {entropy.max().item():.3f}\")\n",
    "        print(f\"Mean: {entropy.mean().item():.3f}\")\n",
    "\n",
    "        print(f\"\\nSparsity stats:\")\n",
    "        print(f\"Min: {sparsity.min().item():.3f}\")\n",
    "        print(f\"Max: {sparsity.max().item():.3f}\")\n",
    "        print(f\"Mean: {sparsity.mean().item():.3f}\")\n",
    "\n",
    "        # Print the thresholds being used\n",
    "        print(f\"\\nThresholds:\")\n",
    "        print(f\"Entropy: [{config['entropy_threshold_low']}, {config['entropy_threshold_high']}]\")\n",
    "        print(f\"Sparsity: [{config['sparsity_min']}, {config['sparsity_max']}]\")\n",
    "\n",
    "    return entropy, sparsity, varentropy\n",
    "\n",
    "def filter_features(acts, config):\n",
    "    \"\"\"\n",
    "    Filter features based on entropy and sparsity.\n",
    "    We are looking at the feature behavior across prompts (we could modify this for tokens, or even for tokens within prompts)\n",
    "    \"\"\"\n",
    "\n",
    "    n_prompts, n_features = acts.shape\n",
    "    entropy, sparsity, varentropy = get_entropy_sparsity_varentropy(acts, config, n_prompts)\n",
    "    \n",
    "    # Apply filtering mask\n",
    "    mask = (entropy > config['entropy_threshold_low']) & \\\n",
    "           (entropy < config['entropy_threshold_high']) & \\\n",
    "           (sparsity > config['sparsity_min']) & \\\n",
    "           (sparsity < config['sparsity_max'])\n",
    "    \n",
    "    print(f\"Kept {mask.sum().item()} out of {n_features} features\")\n",
    "    return acts[:, mask], mask.nonzero(as_tuple=True)[0], entropy, sparsity, varentropy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filtered_acts, original_indices, entropy_data, sparsity_data, varentropy_data = filter_features(acts, config)\n",
    "print(f' after filtering acts.shape: {acts.shape}')\n",
    "\n",
    "if config['visualize_features']:\n",
    "    # Create a DataFrame for entropy and sparsity\n",
    "    df = pd.DataFrame({\n",
    "        'entropy': entropy_data.cpu().numpy(),\n",
    "        'sparsity': sparsity_data.cpu().numpy(),\n",
    "        'varentropy': varentropy_data.cpu().numpy(),\n",
    "    })\n",
    "\n",
    "    px.scatter(df, x='entropy', y='sparsity').show()\n",
    "    px.scatter(df, x='entropy', y='varentropy').show()\n",
    "    px.scatter(df, x='sparsity', y='varentropy').show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy and sparsity visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_quadrants(filtered_acts, n_examples=5):\n",
    "    \"\"\"Analyze features based on their entropy/varentropy quadrants.\n",
    "    \n",
    "    Args:\n",
    "        acts: [n_prompts, n_features] activation tensor\n",
    "        entropy: [n_features] entropy per feature\n",
    "        varentropy: [n_features] variance of entropy per feature\n",
    "        n_examples: number of example features to show per quadrant\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_entropy, filtered_sparsity, filtered_varentropy = get_entropy_sparsity_varentropy(filtered_acts, config, n_prompts)\n",
    "\n",
    "    # Get medians for quadrant splitting\n",
    "    entropy_median = filtered_entropy.median()\n",
    "    varentropy_median = filtered_varentropy.median()\n",
    "    \n",
    "    # Create quadrant masks\n",
    "    q1 = (filtered_entropy <= entropy_median) & (filtered_varentropy <= varentropy_median)  # Low E, Low VE\n",
    "    q2 = (filtered_entropy > entropy_median) & (filtered_varentropy <= varentropy_median)   # High E, Low VE\n",
    "    q3 = (filtered_entropy <= entropy_median) & (filtered_varentropy > varentropy_median)   # Low E, High VE\n",
    "    q4 = (filtered_entropy > entropy_median) & (filtered_varentropy > varentropy_median)    # High E, High VE\n",
    "    \n",
    "    quadrants = {\n",
    "        \"Flowing (Low E, Low VE)\": q1,\n",
    "        \"Careful (High E, Low VE)\": q2,\n",
    "        \"Exploring (Low E, High VE)\": q3,\n",
    "        \"Resampling (High E, High VE)\": q4\n",
    "    }\n",
    "    \n",
    "    # print(\"Feature Distribution in Quadrants:\")\n",
    "    for name, mask in quadrants.items():\n",
    "        n_features = mask.sum().item()\n",
    "        # print(f\"\\n{name}: {n_features} features ({n_features/len(filtered_entropy):.1%})\")\n",
    "        \n",
    "        # Get example features from this quadrant\n",
    "        feature_indices = mask.nonzero(as_tuple=True)[0]\n",
    "        if len(feature_indices) > 0:\n",
    "            sample_indices = feature_indices[torch.randperm(len(feature_indices))[:n_examples]]\n",
    "            \n",
    "            # print(\"\\nExample features:\")\n",
    "            for idx in sample_indices:\n",
    "                # Get activation statistics for this feature\n",
    "                feature_acts = acts[:, idx]\n",
    "                active_prompts = (feature_acts.abs() > config['activation_threshold']).sum().item()\n",
    "                max_activation = feature_acts.abs().max().item()\n",
    "                \n",
    "                # print(f\"\\nFeature {idx}:\")\n",
    "                # print(f\"  Entropy: {filtered_entropy[idx]:.3f}\")\n",
    "                # print(f\"  Varentropy: {filtered_varentropy[idx]:.3f}\")\n",
    "                # print(f\"  Active in {active_prompts}/{len(acts)} prompts\")\n",
    "                # print(f\"  Max activation: {max_activation:.3f}\")\n",
    "                \n",
    "    return quadrants, filtered_entropy, filtered_varentropy\n",
    "\n",
    "# Create a visualization of the quadrants\n",
    "def plot_entropy_quadrants(entropy, varentropy, quadrants):\n",
    "    \"\"\"Create a scatter plot showing feature distribution across quadrants.\"\"\"\n",
    "    import plotly.express as px\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'entropy': entropy.cpu().numpy(),\n",
    "        'varentropy': varentropy.cpu().numpy(),\n",
    "        'quadrant': 'Unknown'\n",
    "    })\n",
    "    \n",
    "    # Assign quadrant labels\n",
    "    for name, mask in quadrants.items():\n",
    "        df.loc[mask.cpu().numpy(), 'quadrant'] = name\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(df, x='entropy', y='varentropy', color='quadrant',\n",
    "                    title='Feature Distribution across Entropy/Varentropy Quadrants',\n",
    "                    labels={'entropy': 'Entropy', 'varentropy': 'Variance of Entropy'})\n",
    "    \n",
    "    # Add median lines\n",
    "    fig.add_hline(y=varentropy.median().item(), line_dash=\"dash\", line_color=\"gray\")\n",
    "    fig.add_vline(x=entropy.median().item(), line_dash=\"dash\", line_color=\"gray\")\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "if config['visualize_features']:\n",
    "    quadrants, filtered_entropy, filtered_varentropy = analyze_feature_quadrants(filtered_acts)\n",
    "    plot_entropy_quadrants(filtered_entropy, filtered_varentropy, quadrants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying UMAP and HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering complete: found 3 clusters with 75.15% noise points\n",
      " after clustering reduced_acts.shape: (7272, 1000)\n",
      " after clustering labels.shape: (7272,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "\n",
    "def apply_umap_preprocessing(normalized_acts, config):\n",
    "\n",
    "    \n",
    "    n_samples, n_dims = normalized_acts.shape\n",
    "        \n",
    "    target_dims = config['umap_components']\n",
    "    \n",
    "    reducer = umap.UMAP(\n",
    "        n_components=target_dims,\n",
    "        n_neighbors=min(config['umap_neighbors'], n_samples - 1),\n",
    "        min_dist=config['umap_min_dist'],\n",
    "        metric=config['umap_metric'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        reduced_acts = reducer.fit_transform(normalized_acts)\n",
    "        print(f\"Applied UMAP reduction: {n_dims}d â†’ {target_dims}d\")\n",
    "        return reduced_acts, normalized_acts\n",
    "    except Exception as e:\n",
    "        print(f\"Error during UMAP reduction: {e}\")\n",
    "        return normalized_acts, normalized_acts\n",
    "\n",
    "\n",
    "def run_hdbscan(reduced_acts, config):\n",
    "    \"\"\"Run HDBSCAN clustering.\"\"\"\n",
    "    # clusterer = hdbscan.HDBSCAN(\n",
    "    #     min_cluster_size=config['hdbscan_min_cluster_size'],\n",
    "    #     min_samples=config['hdbscan_min_samples'],\n",
    "    #     metric=config['hdbscan_metric'],\n",
    "    #     cluster_selection_epsilon=config['hdbscan_cluster_selection_epsilon']\n",
    "    # ) \n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(algorithm='best', alpha=1.0, approx_min_span_tree=True,\n",
    "    gen_min_span_tree=False, leaf_size=40, memory=Memory(None),\n",
    "    metric='precomputed', min_cluster_size=5, min_samples=None, p=None)\n",
    "\n",
    "    return clusterer.fit_predict(distance_matrix)\n",
    "\n",
    "def cluster_features(acts, config):\n",
    "    \"\"\"Cluster features using UMAP preprocessing (if needed) and HDBSCAN.\"\"\"\n",
    "    \n",
    "    acts = acts.T.cpu().numpy()\n",
    "    normalized_acts = acts / (np.linalg.norm(acts, axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # Preprocess with UMAP if enabled\n",
    "    if config['use_umap']:\n",
    "        reduced_acts, normalized_acts = apply_umap_preprocessing(normalized_acts, config)\n",
    "    else:\n",
    "        reduced_acts = normalized_acts\n",
    "    \n",
    "    # Run HDBSCAN clustering\n",
    "    labels = run_hdbscan(reduced_acts, config)\n",
    "    \n",
    "    n_clusters = len(np.unique(labels)) - (1 if -1 in labels else 0)\n",
    "    noise_ratio = np.mean(labels == -1) if -1 in labels else 0\n",
    "    print(f\"Clustering complete: found {n_clusters} clusters with {noise_ratio:.2%} noise points\")\n",
    "    \n",
    "    return labels, normalized_acts\n",
    "\n",
    "\n",
    "labels, reduced_acts = cluster_features(filtered_acts, config)\n",
    "\n",
    "print(f' after clustering reduced_acts.shape: {reduced_acts.shape}')\n",
    "print(f' after clustering labels.shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster prompt analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cluster Analysis Summary ===\n",
      "Total Features: 7272\n",
      "Number of Clusters: 3\n",
      "Noise Points: 5465 (75.15%)\n",
      "\n",
      "=== Noise Cluster ===\n",
      "Size: 5465 features (75.15% of total)\n",
      "Feature Indices: [4, 5, 9, 10, 14, 21, 25, 26, 33, 37, 40, 42, 44, 45, 48, 65, 69, 83, 89, 94, 99, 100, 110, 115, 125, 128, 140, 144, 154, 160, 174, 176, 186, 197, 200, 209, 213, 216, 218, 219, 222, 227, 235, 240, 253, 257, 265, 267, 290, 292, 298, 310, 314, 317, 321, 325, 332, 340, 341, 344, 345, 354, 356, 363, 372, 381, 383, 387, 392, 395, 402, 410, 418, 426, 427, 436, 439, 442, 444, 447, 455, 473, 477, 483, 484, 502, 507, 513, 521, 527, 529, 532, 537, 538, 541, 543, 547, 558, 564, 569, 574, 584, 603, 607, 614, 617, 621, 628, 635, 649, 669, 672, 687, 695, 701, 706, 708, 709, 738, 745, 751, 766, 767, 771, 779, 780, 781, 782, 784, 786, 790, 791, 797, 798, 803, 804, 805, 817, 821, 835, 836, 847, 858, 859, 868, 883, 887, 898, 900, 901, 922, 923, 925, 930, 933, 935, 946, 948, 952, 953, 963, 964, 987, 991, 1021, 1028, 1032, 1033, 1035, 1038, 1051, 1054, 1058, 1066, 1076, 1082, 1083, 1088, 1098, 1113, 1114, 1120, 1123, 1130, 1132, 1133, 1148, 1153, 1155, 1163, 1172, 1178, 1182, 1189, 1203, 1209, 1210, 1211, 1255, 1257, 1262, 1264, 1269, 1271, 1277, 1279, 1282, 1283, 1286, 1292, 1300, 1309, 1312, 1315, 1336, 1342, 1344, 1366, 1367, 1368, 1375, 1382, 1391, 1396, 1397, 1399, 1406, 1407, 1414, 1421, 1427, 1431, 1444, 1452, 1456, 1463, 1470, 1471, 1475, 1484, 1499, 1500, 1503, 1507, 1511, 1513, 1526, 1543, 1546, 1557, 1577, 1581, 1588, 1594, 1597, 1602, 1605, 1608, 1617, 1618, 1624, 1630, 1632, 1634, 1640, 1643, 1652, 1658, 1669, 1676, 1692, 1698, 1699, 1719, 1732, 1744, 1747, 1756, 1768, 1773, 1778, 1781, 1787, 1799, 1810, 1813, 1822, 1825, 1829, 1834, 1835, 1843, 1861, 1863, 1869, 1902, 1903, 1906, 1914, 1915, 1919, 1921, 1926, 1931, 1939, 1941, 1943, 1976, 1979, 1998, 1999, 2005, 2006, 2013, 2027, 2037, 2058, 2066, 2071, 2072, 2082, 2083, 2085, 2094, 2098, 2101, 2103, 2106, 2114, 2125, 2130, 2141, 2144, 2154, 2163, 2164, 2169, 2184, 2187, 2193, 2194, 2199, 2200, 2202, 2233, 2236, 2240, 2249, 2258, 2268, 2278, 2283, 2285, 2300, 2322, 2325, 2326, 2328, 2330, 2334, 2336, 2353, 2359, 2363, 2367, 2377, 2380, 2387, 2389, 2396, 2432, 2437, 2461, 2471, 2480, 2485, 2490, 2507, 2508, 2514, 2518, 2520, 2528, 2530, 2534, 2539, 2545, 2547, 2548, 2557, 2563, 2564, 2565, 2574, 2575, 2583, 2596, 2600, 2601, 2605, 2606, 2614, 2617, 2623, 2625, 2627, 2637, 2638, 2641, 2644, 2655, 2672, 2687, 2706, 2717, 2724, 2726, 2735, 2738, 2740, 2742, 2746, 2760, 2764, 2765, 2767, 2768, 2769, 2771, 2774, 2776, 2789, 2799, 2805, 2807, 2808, 2812, 2817, 2827, 2833, 2842, 2847, 2854, 2855, 2861, 2869, 2871, 2876, 2879, 2882, 2889, 2891, 2901, 2915, 2920, 2929, 2939, 2943, 2946, 2948, 2955, 2960, 2970, 2977, 2978, 2989, 2993, 3002, 3019, 3028, 3032, 3033, 3039, 3043, 3046, 3052, 3054, 3055, 3056, 3060, 3064, 3065, 3068, 3073, 3084, 3087, 3090, 3105, 3112, 3114, 3118, 3120, 3127, 3132, 3136, 3158, 3160, 3183, 3196, 3203, 3207, 3210, 3215, 3218, 3220, 3223, 3227, 3237, 3246, 3253, 3269, 3273, 3279, 3288, 3289, 3298, 3302, 3307, 3312, 3324, 3336, 3351, 3364, 3365, 3368, 3370, 3375, 3383, 3390, 3396, 3401, 3404, 3406, 3410, 3421, 3423, 3434, 3435, 3437, 3440, 3444, 3447, 3455, 3467, 3471, 3490, 3505, 3506, 3518, 3523, 3531, 3546, 3565, 3568, 3578, 3581, 3582, 3586, 3588, 3590, 3594, 3600, 3604, 3608, 3628, 3629, 3631, 3632, 3634, 3635, 3636, 3639, 3640, 3646, 3658, 3664, 3666, 3669, 3678, 3679, 3681, 3691, 3698, 3699, 3700, 3706, 3713, 3723, 3728, 3729, 3732, 3734, 3738, 3751, 3754, 3763, 3766, 3769, 3778, 3783, 3784, 3789, 3791, 3794, 3801, 3805, 3815, 3817, 3824, 3825, 3841, 3848, 3849, 3852, 3857, 3863, 3873, 3875, 3881, 3884, 3891, 3893, 3896, 3902, 3905, 3913, 3914, 3920, 3923, 3926, 3945, 3946, 3961, 3966, 3970, 3982, 3986, 3987, 3996, 3999, 4002, 4004, 4006, 4010, 4011, 4015, 4021, 4029, 4038, 4043, 4045, 4047, 4052, 4055, 4060, 4071, 4079, 4091, 4092, 4112, 4124, 4128, 4154, 4165, 4167, 4170, 4171, 4173, 4175, 4188, 4192, 4197, 4201, 4213, 4217, 4218, 4220, 4223, 4231, 4235, 4236, 4238, 4249, 4251, 4256, 4270, 4278, 4300, 4301, 4308, 4309, 4310, 4313, 4317, 4323, 4334, 4340, 4342, 4361, 4366, 4375, 4382, 4392, 4397, 4413, 4417, 4418, 4423, 4429, 4437, 4438, 4446, 4450, 4454, 4457, 4460, 4462, 4471, 4476, 4484, 4492, 4500, 4508, 4510, 4513, 4515, 4517, 4520, 4532, 4534, 4541, 4556, 4571, 4581, 4582, 4584, 4585, 4588, 4600, 4604, 4616, 4619, 4620, 4623, 4627, 4633, 4661, 4670, 4671, 4685, 4690, 4691, 4693, 4694, 4703, 4711, 4712, 4733, 4736, 4745, 4750, 4752, 4755, 4765, 4779, 4781, 4786, 4798, 4800, 4805, 4808, 4814, 4816, 4819, 4821, 4830, 4846, 4847, 4852, 4855, 4861, 4876, 4884, 4886, 4891, 4893, 4895, 4896, 4904, 4911, 4913, 4917, 4921, 4931, 4941, 4942, 4943, 4944, 4951, 4953, 4955, 4957, 4960, 4968, 4970, 4974, 4975, 4988, 4989, 4991, 4996, 5006, 5009, 5013, 5018, 5021, 5030, 5048, 5052, 5056, 5063, 5065, 5104, 5116, 5124, 5129, 5130, 5136, 5137, 5157, 5158, 5159, 5161, 5199, 5202, 5204, 5216, 5223, 5229, 5231, 5255, 5261, 5265, 5270, 5272, 5274, 5286, 5290, 5295, 5298, 5302, 5309, 5311, 5316, 5317, 5320, 5321, 5327, 5333, 5336, 5354, 5368, 5371, 5383, 5392, 5395, 5402, 5413, 5417, 5432, 5445, 5448, 5450, 5452, 5453, 5458, 5464, 5469, 5490, 5494, 5498, 5508, 5537, 5544, 5562, 5567, 5572, 5577, 5579, 5589, 5596, 5597, 5598, 5599, 5609, 5611, 5615, 5616, 5621, 5638, 5640, 5649, 5654, 5666, 5668, 5670, 5672, 5673, 5677, 5686, 5688, 5702, 5706, 5716, 5723, 5729, 5734, 5737, 5740, 5748, 5758, 5761, 5764, 5770, 5788, 5795, 5810, 5820, 5823, 5827, 5828, 5829, 5836, 5844, 5856, 5858, 5859, 5873, 5875, 5876, 5903, 5906, 5907, 5910, 5913, 5919, 5933, 5946, 5947, 5954, 5975, 5979, 5981, 5987, 5994, 5996, 5997, 5998, 5999, 6008, 6011, 6013, 6014, 6019, 6026, 6029, 6040, 6042, 6058, 6065, 6074, 6075, 6078, 6081, 6095, 6102, 6103, 6104, 6105, 6106, 6107, 6117, 6122, 6125, 6130, 6139, 6141, 6142, 6144, 6151, 6154, 6159, 6161, 6174, 6176, 6182, 6194, 6230, 6232, 6234, 6235, 6236, 6237, 6238, 6242, 6245, 6257, 6260, 6265, 6267, 6269, 6279, 6284, 6288, 6290, 6293, 6310, 6312, 6314, 6318, 6319, 6330, 6336, 6340, 6352, 6357, 6361, 6375, 6385, 6388, 6397, 6401, 6402, 6413, 6414, 6417, 6419, 6426, 6432, 6435, 6443, 6446, 6448, 6450, 6455, 6457, 6459, 6461, 6462, 6487, 6497, 6502, 6505, 6508, 6510, 6515, 6517, 6521, 6531, 6532, 6534, 6544, 6550, 6556, 6567, 6573, 6592, 6604, 6608, 6615, 6617, 6621, 6623, 6635, 6637, 6644, 6646, 6647, 6652, 6661, 6664, 6671, 6675, 6684, 6688, 6691, 6702, 6703, 6704, 6710, 6725, 6727, 6731, 6733, 6739, 6741, 6748, 6762, 6773, 6775, 6782, 6810, 6811, 6824, 6833, 6842, 6844, 6847, 6853, 6854, 6862, 6865, 6868, 6869, 6871, 6881, 6886, 6898, 6900, 6901, 6907, 6908, 6917, 6918, 6922, 6926, 6927, 6930, 6932, 6934, 6939, 6949, 6950, 6952, 6958, 6962, 6963, 6965, 6977, 6979, 6987, 6991, 6993, 6995, 6997, 6998, 7000, 7009, 7013, 7022, 7025, 7034, 7041, 7042, 7043, 7047, 7051, 7061, 7070, 7078, 7091, 7093, 7106, 7107, 7117, 7123, 7126, 7145, 7146, 7148, 7150, 7151, 7152, 7156, 7160, 7162, 7168, 7178, 7180, 7195, 7201, 7207, 7211, 7216, 7218, 7219, 7220, 7226, 7228, 7235, 7237, 7239, 7245, 7252, 7253, 7259, 7260, 7281, 7287, 7289, 7296, 7315, 7316, 7320, 7326, 7327, 7331, 7332, 7339, 7345, 7351, 7357, 7366, 7369, 7386, 7406, 7408, 7410, 7412, 7416, 7420, 7423, 7427, 7429, 7431, 7436, 7438, 7439, 7442, 7452, 7455, 7461, 7465, 7468, 7486, 7489, 7498, 7509, 7519, 7536, 7540, 7550, 7552, 7562, 7568, 7571, 7576, 7580, 7592, 7600, 7610, 7616, 7617, 7627, 7628, 7630, 7634, 7639, 7641, 7644, 7667, 7689, 7698, 7703, 7713, 7715, 7723, 7728, 7730, 7732, 7735, 7738, 7745, 7754, 7767, 7770, 7772, 7776, 7779, 7780, 7786, 7789, 7796, 7798, 7804, 7810, 7811, 7813, 7822, 7831, 7834, 7837, 7838, 7843, 7845, 7847, 7848, 7849, 7850, 7855, 7859, 7860, 7861, 7882, 7884, 7885, 7887, 7900, 7901, 7904, 7905, 7910, 7925, 7943, 7945, 7946, 7948, 7950, 7957, 7960, 7964, 7973, 7982, 7983, 7986, 7989, 7998, 7999, 8004, 8007, 8011, 8014, 8017, 8020, 8029, 8036, 8041, 8046, 8047, 8058, 8066, 8070, 8071, 8080, 8087, 8090, 8096, 8097, 8100, 8111, 8120, 8127, 8146, 8148, 8149, 8150, 8152, 8162, 8163, 8172, 8175, 8178, 8188, 8191, 8197, 8204, 8218, 8223, 8224, 8226, 8237, 8241, 8242, 8267, 8277, 8286, 8287, 8296, 8305, 8314, 8319, 8320, 8321, 8324, 8325, 8334, 8335, 8338, 8340, 8341, 8354, 8356, 8375, 8377, 8379, 8380, 8386, 8405, 8414, 8417, 8419, 8424, 8425, 8429, 8431, 8432, 8436, 8437, 8448, 8450, 8454, 8458, 8460, 8465, 8472, 8474, 8475, 8481, 8483, 8490, 8495, 8498, 8511, 8517, 8521, 8529, 8549, 8553, 8556, 8560, 8565, 8566, 8571, 8574, 8575, 8580, 8599, 8605, 8608, 8610, 8611, 8613, 8617, 8619, 8623, 8626, 8627, 8630, 8632, 8633, 8635, 8636, 8638, 8648, 8651, 8655, 8658, 8659, 8667, 8670, 8671, 8672, 8683, 8686, 8687, 8689, 8700, 8703, 8706, 8727, 8729, 8740, 8745, 8746, 8752, 8755, 8760, 8762, 8782, 8793, 8801, 8804, 8806, 8809, 8811, 8813, 8823, 8825, 8826, 8830, 8831, 8834, 8840, 8843, 8846, 8861, 8865, 8874, 8879, 8897, 8915, 8916, 8928, 8938, 8947, 8948, 8959, 8964, 8969, 8980, 9002, 9013, 9015, 9025, 9026, 9027, 9032, 9049, 9054, 9058, 9060, 9062, 9082, 9089, 9095, 9109, 9120, 9122, 9128, 9129, 9131, 9140, 9154, 9156, 9162, 9168, 9169, 9170, 9175, 9178, 9181, 9182, 9185, 9187, 9197, 9200, 9213, 9215, 9223, 9226, 9240, 9245, 9258, 9259, 9264, 9269, 9275, 9286, 9294, 9298, 9302, 9316, 9334, 9336, 9344, 9352, 9353, 9358, 9359, 9360, 9361, 9363, 9366, 9367, 9376, 9379, 9381, 9382, 9383, 9395, 9397, 9407, 9412, 9423, 9478, 9479, 9480, 9482, 9483, 9485, 9491, 9493, 9495, 9498, 9500, 9513, 9517, 9523, 9525, 9530, 9536, 9538, 9541, 9542, 9555, 9560, 9567, 9568, 9574, 9587, 9594, 9598, 9601, 9602, 9607, 9617, 9622, 9626, 9633, 9636, 9657, 9664, 9680, 9690, 9714, 9731, 9732, 9746, 9747, 9749, 9753, 9754, 9755, 9757, 9771, 9785, 9787, 9789, 9801, 9843, 9844, 9848, 9861, 9863, 9869, 9877, 9896, 9901, 9906, 9907, 9917, 9949, 9951, 9954, 9956, 9961, 9963, 9966, 9974, 9975, 9996, 10003, 10010, 10011, 10017, 10020, 10025, 10030, 10033, 10038, 10042, 10057, 10061, 10062, 10069, 10073, 10075, 10081, 10085, 10093, 10099, 10107, 10123, 10130, 10131, 10132, 10141, 10142, 10144, 10149, 10159, 10166, 10167, 10191, 10198, 10205, 10209, 10232, 10247, 10249, 10255, 10256, 10277, 10280, 10289, 10294, 10295, 10309, 10315, 10321, 10322, 10323, 10328, 10331, 10342, 10357, 10361, 10372, 10376, 10378, 10380, 10381, 10382, 10389, 10391, 10392, 10402, 10409, 10413, 10414, 10418, 10421, 10423, 10430, 10438, 10443, 10446, 10451, 10457, 10458, 10467, 10481, 10497, 10503, 10512, 10524, 10535, 10537, 10541, 10548, 10552, 10553, 10561, 10562, 10567, 10571, 10577, 10580, 10582, 10584, 10591, 10601, 10603, 10604, 10615, 10616, 10623, 10633, 10639, 10642, 10649, 10659, 10672, 10673, 10677, 10689, 10696, 10699, 10701, 10715, 10716, 10724, 10729, 10733, 10738, 10745, 10746, 10763, 10769, 10771, 10773, 10787, 10791, 10793, 10805, 10808, 10817, 10822, 10833, 10835, 10840, 10861, 10862, 10865, 10890, 10891, 10910, 10912, 10921, 10922, 10926, 10931, 10935, 10936, 10954, 10964, 10967, 10970, 10974, 10975, 11002, 11013, 11019, 11023, 11027, 11028, 11029, 11036, 11039, 11047, 11052, 11056, 11057, 11060, 11062, 11063, 11079, 11082, 11092, 11110, 11117, 11120, 11122, 11130, 11133, 11153, 11174, 11182, 11189, 11203, 11208, 11220, 11223, 11224, 11230, 11234, 11237, 11239, 11240, 11245, 11251, 11253, 11261, 11263, 11264, 11273, 11276, 11280, 11300, 11307, 11309, 11326, 11335, 11339, 11350, 11354, 11366, 11372, 11374, 11385, 11398, 11411, 11424, 11432, 11434, 11439, 11446, 11450, 11460, 11464, 11465, 11467, 11475, 11478, 11500, 11505, 11540, 11542, 11550, 11552, 11556, 11558, 11564, 11568, 11578, 11596, 11600, 11603, 11614, 11617, 11625, 11628, 11647, 11660, 11662, 11664, 11668, 11674, 11679, 11680, 11684, 11692, 11706, 11707, 11723, 11725, 11727, 11729, 11738, 11740, 11742, 11750, 11756, 11757, 11765, 11773, 11774, 11783, 11796, 11800, 11811, 11812, 11824, 11833, 11841, 11843, 11856, 11864, 11869, 11873, 11889, 11903, 11909, 11912, 11913, 11914, 11915, 11918, 11920, 11924, 11928, 11930, 11939, 11946, 11961, 11963, 11965, 11968, 11972, 11984, 11985, 11997, 12010, 12018, 12030, 12036, 12043, 12057, 12062, 12063, 12079, 12087, 12093, 12094, 12098, 12107, 12116, 12129, 12134, 12135, 12137, 12140, 12156, 12177, 12181, 12188, 12191, 12194, 12210, 12213, 12216, 12217, 12229, 12231, 12233, 12236, 12251, 12252, 12255, 12257, 12258, 12265, 12267, 12274, 12277, 12280, 12283, 12284, 12305, 12311, 12313, 12315, 12319, 12323, 12324, 12326, 12350, 12353, 12370, 12374, 12376, 12380, 12381, 12383, 12384, 12388, 12391, 12396, 12398, 12402, 12412, 12413, 12420, 12421, 12433, 12434, 12442, 12451, 12455, 12459, 12468, 12478, 12487, 12494, 12497, 12506, 12512, 12522, 12527, 12530, 12531, 12532, 12539, 12541, 12543, 12544, 12549, 12550, 12551, 12555, 12556, 12558, 12571, 12572, 12574, 12587, 12592, 12598, 12607, 12635, 12641, 12643, 12644, 12645, 12647, 12649, 12654, 12656, 12658, 12665, 12671, 12674, 12676, 12683, 12686, 12691, 12698, 12702, 12706, 12711, 12713, 12715, 12719, 12721, 12736, 12738, 12744, 12751, 12754, 12759, 12760, 12763, 12768, 12769, 12773, 12776, 12777, 12784, 12787, 12789, 12797, 12806, 12820, 12823, 12828, 12829, 12831, 12838, 12845, 12864, 12871, 12882, 12888, 12894, 12895, 12902, 12911, 12912, 12922, 12933, 12944, 12950, 12953, 12957, 12961, 12964, 12967, 12968, 12971, 12978, 12979, 12980, 12986, 12987, 12989, 12990, 12991, 12992, 12994, 13003, 13011, 13015, 13019, 13021, 13027, 13028, 13050, 13051, 13074, 13081, 13086, 13089, 13098, 13099, 13101, 13104, 13107, 13111, 13112, 13113, 13125, 13126, 13127, 13134, 13135, 13144, 13150, 13160, 13164, 13166, 13169, 13170, 13171, 13178, 13181, 13184, 13185, 13191, 13195, 13200, 13208, 13212, 13213, 13237, 13241, 13243, 13245, 13251, 13252, 13253, 13266, 13267, 13275, 13276, 13282, 13292, 13293, 13297, 13322, 13323, 13331, 13337, 13340, 13345, 13349, 13353, 13359, 13361, 13362, 13365, 13379, 13392, 13414, 13419, 13421, 13428, 13434, 13439, 13440, 13459, 13468, 13479, 13487, 13496, 13500, 13502, 13503, 13504, 13510, 13511, 13514, 13519, 13520, 13535, 13536, 13540, 13550, 13566, 13570, 13581, 13582, 13591, 13620, 13623, 13624, 13636, 13639, 13641, 13655, 13672, 13675, 13679, 13684, 13685, 13693, 13702, 13704, 13705, 13713, 13726, 13729, 13740, 13743, 13747, 13748, 13756, 13770, 13772, 13776, 13779, 13787, 13794, 13806, 13808, 13811, 13814, 13824, 13837, 13838, 13850, 13852, 13859, 13863, 13867, 13874, 13877, 13892, 13894, 13907, 13910, 13912, 13915, 13928, 13936, 13941, 13946, 13950, 13959, 13965, 13968, 13985, 13997, 13998, 14001, 14005, 14012, 14013, 14022, 14024, 14025, 14032, 14034, 14035, 14041, 14044, 14055, 14060, 14062, 14063, 14072, 14073, 14074, 14078, 14086, 14088, 14089, 14103, 14108, 14111, 14116, 14124, 14131, 14133, 14147, 14150, 14155, 14163, 14164, 14165, 14170, 14174, 14177, 14194, 14198, 14203, 14213, 14230, 14241, 14245, 14253, 14260, 14291, 14296, 14298, 14299, 14300, 14317, 14341, 14344, 14345, 14352, 14356, 14364, 14369, 14375, 14378, 14379, 14391, 14392, 14393, 14404, 14411, 14413, 14419, 14420, 14439, 14475, 14478, 14491, 14497, 14502, 14512, 14516, 14526, 14540, 14553, 14563, 14569, 14570, 14576, 14577, 14578, 14585, 14602, 14603, 14606, 14614, 14626, 14627, 14646, 14648, 14658, 14665, 14668, 14682, 14683, 14686, 14688, 14691, 14693, 14694, 14708, 14709, 14710, 14719, 14722, 14728, 14734, 14738, 14739, 14742, 14750, 14760, 14761, 14766, 14768, 14774, 14776, 14779, 14780, 14792, 14797, 14799, 14808, 14811, 14827, 14831, 14840, 14847, 14848, 14849, 14860, 14865, 14869, 14871, 14875, 14879, 14880, 14889, 14922, 14923, 14927, 14928, 14933, 14943, 14944, 14946, 14950, 14952, 14960, 14964, 14979, 14980, 14984, 14985, 14994, 15003, 15027, 15035, 15036, 15048, 15057, 15063, 15069, 15070, 15075, 15079, 15081, 15083, 15084, 15102, 15103, 15104, 15107, 15111, 15112, 15115, 15129, 15131, 15134, 15148, 15150, 15154, 15158, 15159, 15166, 15172, 15184, 15203, 15204, 15209, 15220, 15224, 15232, 15233, 15237, 15238, 15239, 15240, 15244, 15252, 15267, 15273, 15283, 15298, 15305, 15309, 15311, 15315, 15325, 15329, 15336, 15369, 15377, 15379, 15386, 15387, 15391, 15395, 15397, 15402, 15415, 15417, 15420, 15421, 15433, 15438, 15441, 15465, 15472, 15478, 15479, 15480, 15487, 15493, 15500, 15505, 15508, 15509, 15521, 15523, 15545, 15552, 15559, 15567, 15568, 15571, 15575, 15578, 15582, 15586, 15605, 15607, 15626, 15639, 15640, 15641, 15655, 15665, 15673, 15677, 15681, 15691, 15692, 15693, 15702, 15704, 15708, 15710, 15722, 15729, 15730, 15732, 15733, 15737, 15742, 15743, 15744, 15746, 15748, 15751, 15765, 15774, 15776, 15782, 15789, 15794, 15795, 15798, 15802, 15810, 15816, 15830, 15832, 15841, 15842, 15856, 15866, 15868, 15869, 15894, 15896, 15901, 15903, 15908, 15911, 15913, 15920, 15921, 15925, 15931, 15952, 15955, 15959, 15963, 15965, 15980, 15993, 15995, 15996, 16022, 16025, 16030, 16043, 16050, 16058, 16062, 16070, 16083, 16092, 16098, 16105, 16110, 16114, 16117, 16118, 16125, 16129, 16141, 16144, 16151, 16152, 16158, 16182, 16184, 16187, 16188, 16201, 16202, 16218, 16219, 16220, 16223, 16224, 16225, 16227, 16229, 16235, 16242, 16252, 16253, 16255, 16256, 16264, 16273, 16275, 16277, 16280, 16306, 16308, 16315, 16321, 16330, 16339, 16350, 16352, 16355, 16357, 16362, 16380, 16381, 16410, 16414, 16434, 16452, 16453, 16454, 16458, 16459, 16470, 16475, 16484, 16487, 16488, 16491, 16499, 16500, 16506, 16517, 16533, 16538, 16548, 16568, 16569, 16575, 16580, 16587, 16589, 16594, 16607, 16609, 16618, 16620, 16623, 16629, 16637, 16653, 16655, 16657, 16663, 16668, 16683, 16685, 16693, 16698, 16701, 16709, 16712, 16716, 16722, 16724, 16725, 16736, 16739, 16741, 16747, 16752, 16760, 16770, 16778, 16782, 16798, 16799, 16802, 16805, 16807, 16813, 16816, 16823, 16824, 16833, 16834, 16836, 16842, 16843, 16859, 16865, 16867, 16871, 16877, 16878, 16881, 16885, 16889, 16890, 16897, 16899, 16906, 16909, 16910, 16912, 16918, 16920, 16939, 16940, 16943, 16949, 16955, 16965, 16970, 16972, 16978, 16982, 17007, 17025, 17028, 17042, 17048, 17064, 17068, 17069, 17072, 17079, 17087, 17088, 17090, 17098, 17114, 17115, 17118, 17122, 17130, 17136, 17140, 17147, 17153, 17161, 17168, 17176, 17187, 17192, 17194, 17196, 17212, 17219, 17223, 17225, 17239, 17247, 17261, 17265, 17272, 17277, 17280, 17282, 17293, 17304, 17305, 17320, 17330, 17331, 17337, 17340, 17341, 17344, 17356, 17364, 17372, 17378, 17381, 17389, 17392, 17395, 17403, 17413, 17419, 17426, 17430, 17438, 17441, 17447, 17449, 17450, 17455, 17457, 17481, 17483, 17484, 17489, 17491, 17493, 17494, 17508, 17513, 17518, 17522, 17526, 17528, 17529, 17532, 17534, 17555, 17557, 17565, 17570, 17574, 17577, 17590, 17595, 17599, 17603, 17609, 17613, 17614, 17619, 17626, 17629, 17635, 17638, 17645, 17657, 17661, 17671, 17679, 17683, 17691, 17700, 17701, 17703, 17706, 17716, 17730, 17731, 17741, 17745, 17774, 17777, 17778, 17789, 17793, 17797, 17798, 17800, 17802, 17804, 17810, 17812, 17815, 17825, 17832, 17841, 17851, 17856, 17866, 17872, 17877, 17888, 17902, 17908, 17915, 17919, 17923, 17942, 17944, 17960, 17961, 17962, 17966, 17967, 17970, 17974, 17975, 17982, 17983, 17984, 17985, 17992, 18006, 18009, 18012, 18024, 18025, 18026, 18028, 18030, 18034, 18036, 18044, 18052, 18056, 18067, 18077, 18078, 18090, 18094, 18106, 18114, 18115, 18120, 18122, 18123, 18126, 18128, 18133, 18139, 18148, 18150, 18151, 18169, 18189, 18191, 18194, 18198, 18199, 18204, 18208, 18211, 18213, 18223, 18229, 18240, 18242, 18247, 18249, 18254, 18263, 18268, 18276, 18277, 18278, 18289, 18297, 18301, 18308, 18309, 18315, 18318, 18319, 18320, 18326, 18328, 18336, 18340, 18344, 18353, 18357, 18360, 18365, 18366, 18367, 18372, 18373, 18379, 18389, 18392, 18408, 18410, 18425, 18433, 18446, 18463, 18471, 18477, 18481, 18482, 18486, 18489, 18494, 18501, 18503, 18505, 18509, 18510, 18514, 18520, 18527, 18530, 18539, 18541, 18547, 18550, 18559, 18561, 18564, 18566, 18576, 18578, 18579, 18587, 18593, 18601, 18606, 18609, 18618, 18619, 18622, 18627, 18640, 18646, 18668, 18673, 18676, 18682, 18686, 18687, 18688, 18690, 18695, 18700, 18703, 18705, 18712, 18714, 18719, 18727, 18728, 18730, 18742, 18747, 18748, 18749, 18759, 18760, 18763, 18771, 18773, 18774, 18775, 18789, 18795, 18799, 18801, 18814, 18815, 18824, 18830, 18836, 18843, 18846, 18863, 18868, 18872, 18884, 18887, 18902, 18910, 18912, 18918, 18928, 18930, 18950, 18958, 18967, 18975, 18976, 18979, 18985, 18986, 18989, 19003, 19007, 19013, 19020, 19021, 19027, 19031, 19032, 19033, 19041, 19050, 19051, 19052, 19054, 19068, 19069, 19075, 19080, 19083, 19084, 19104, 19108, 19110, 19124, 19125, 19145, 19148, 19169, 19171, 19176, 19180, 19181, 19185, 19199, 19206, 19209, 19212, 19224, 19228, 19229, 19234, 19244, 19247, 19249, 19250, 19252, 19253, 19258, 19261, 19262, 19267, 19270, 19272, 19273, 19280, 19288, 19301, 19306, 19309, 19311, 19316, 19318, 19327, 19334, 19335, 19336, 19346, 19357, 19368, 19375, 19379, 19380, 19383, 19386, 19388, 19391, 19400, 19402, 19407, 19411, 19417, 19418, 19419, 19421, 19433, 19443, 19460, 19462, 19465, 19494, 19495, 19501, 19507, 19518, 19519, 19537, 19540, 19542, 19547, 19549, 19550, 19554, 19565, 19570, 19571, 19574, 19577, 19579, 19580, 19595, 19602, 19603, 19610, 19611, 19620, 19621, 19622, 19629, 19630, 19633, 19638, 19649, 19669, 19671, 19677, 19684, 19687, 19688, 19695, 19697, 19701, 19703, 19704, 19713, 19722, 19727, 19750, 19759, 19767, 19774, 19777, 19783, 19787, 19788, 19789, 19790, 19811, 19814, 19819, 19830, 19835, 19837, 19840, 19842, 19847, 19849, 19862, 19875, 19885, 19892, 19899, 19901, 19924, 19951, 19952, 19959, 19966, 19977, 19981, 19982, 19985, 19994, 20024, 20025, 20026, 20028, 20029, 20037, 20045, 20047, 20048, 20057, 20058, 20068, 20079, 20084, 20091, 20109, 20124, 20163, 20164, 20172, 20173, 20174, 20188, 20191, 20193, 20198, 20201, 20216, 20225, 20252, 20256, 20257, 20259, 20261, 20265, 20268, 20280, 20284, 20285, 20289, 20300, 20317, 20321, 20323, 20335, 20338, 20339, 20343, 20347, 20355, 20358, 20362, 20363, 20366, 20369, 20373, 20375, 20376, 20401, 20407, 20416, 20430, 20452, 20453, 20462, 20466, 20471, 20475, 20476, 20485, 20486, 20487, 20493, 20496, 20503, 20509, 20512, 20513, 20519, 20521, 20526, 20540, 20545, 20547, 20552, 20553, 20562, 20565, 20578, 20579, 20592, 20596, 20598, 20602, 20605, 20612, 20623, 20627, 20629, 20630, 20631, 20635, 20637, 20639, 20640, 20643, 20654, 20656, 20678, 20681, 20687, 20714, 20715, 20728, 20729, 20730, 20733, 20738, 20753, 20760, 20769, 20772, 20776, 20783, 20785, 20786, 20790, 20797, 20802, 20822, 20826, 20831, 20836, 20839, 20842, 20846, 20847, 20859, 20873, 20884, 20896, 20912, 20914, 20920, 20921, 20924, 20930, 20934, 20944, 20946, 20947, 20949, 20950, 20952, 20965, 20971, 20972, 20985, 20986, 20994, 21021, 21027, 21037, 21050, 21051, 21052, 21059, 21060, 21064, 21070, 21073, 21075, 21078, 21080, 21107, 21108, 21117, 21120, 21127, 21145, 21146, 21148, 21153, 21154, 21155, 21157, 21161, 21163, 21168, 21169, 21171, 21178, 21182, 21195, 21217, 21230, 21239, 21243, 21246, 21265, 21268, 21273, 21274, 21275, 21277, 21278, 21280, 21290, 21295, 21297, 21308, 21321, 21323, 21328, 21336, 21339, 21345, 21347, 21348, 21355, 21356, 21357, 21370, 21373, 21376, 21377, 21379, 21387, 21396, 21398, 21409, 21412, 21417, 21429, 21439, 21440, 21446, 21469, 21472, 21477, 21479, 21482, 21496, 21507, 21510, 21518, 21521, 21523, 21525, 21531, 21537, 21541, 21550, 21557, 21565, 21566, 21575, 21582, 21590, 21610, 21617, 21622, 21624, 21626, 21634, 21645, 21646, 21651, 21666, 21669, 21680, 21681, 21682, 21688, 21695, 21700, 21701, 21708, 21714, 21717, 21720, 21733, 21737, 21742, 21747, 21748, 21749, 21751, 21762, 21777, 21782, 21788, 21791, 21794, 21800, 21808, 21809, 21814, 21841, 21842, 21843, 21847, 21848, 21864, 21867, 21871, 21872, 21877, 21881, 21885, 21895, 21900, 21913, 21914, 21917, 21918, 21920, 21922, 21926, 21927, 21933, 21934, 21946, 21956, 21960, 21961, 21976, 21978, 21993, 22006, 22014, 22018, 22023, 22029, 22030, 22033, 22035, 22036, 22038, 22041, 22063, 22067, 22071, 22072, 22074, 22080, 22086, 22099, 22109, 22114, 22117, 22119, 22122, 22124, 22126, 22132, 22135, 22139, 22144, 22150, 22157, 22174, 22190, 22196, 22202, 22209, 22231, 22232, 22244, 22259, 22267, 22273, 22276, 22287, 22300, 22302, 22305, 22312, 22319, 22320, 22321, 22327, 22331, 22360, 22361, 22373, 22376, 22378, 22398, 22402, 22403, 22416, 22418, 22419, 22428, 22433, 22443, 22450, 22454, 22460, 22472, 22476, 22479, 22490, 22508, 22510, 22514, 22516, 22526, 22530, 22540, 22543, 22544, 22547, 22554, 22558, 22566, 22569, 22570, 22571, 22581, 22584, 22607, 22623, 22629, 22630, 22631, 22635, 22642, 22647, 22651, 22653, 22661, 22668, 22673, 22675, 22678, 22685, 22692, 22700, 22727, 22729, 22740, 22751, 22755, 22758, 22762, 22781, 22788, 22798, 22801, 22803, 22811, 22812, 22832, 22838, 22839, 22846, 22849, 22850, 22854, 22871, 22872, 22873, 22880, 22881, 22891, 22893, 22894, 22903, 22907, 22908, 22922, 22929, 22931, 22932, 22934, 22959, 22960, 22972, 22976, 22988, 22990, 23002, 23003, 23014, 23028, 23035, 23041, 23043, 23044, 23062, 23063, 23065, 23069, 23085, 23088, 23091, 23094, 23095, 23096, 23097, 23098, 23105, 23112, 23117, 23120, 23130, 23133, 23136, 23140, 23141, 23143, 23155, 23163, 23171, 23174, 23176, 23181, 23188, 23190, 23194, 23195, 23196, 23197, 23200, 23205, 23218, 23219, 23234, 23236, 23241, 23242, 23243, 23249, 23251, 23252, 23260, 23264, 23273, 23292, 23303, 23304, 23310, 23315, 23316, 23317, 23340, 23346, 23352, 23355, 23358, 23359, 23364, 23367, 23368, 23370, 23378, 23388, 23389, 23391, 23403, 23411, 23419, 23422, 23431, 23440, 23445, 23448, 23457, 23464, 23475, 23490, 23506, 23516, 23522, 23535, 23536, 23539, 23550, 23551, 23555, 23559, 23569, 23570, 23574, 23579, 23580, 23582, 23598, 23599, 23603, 23610, 23611, 23614, 23615, 23623, 23634, 23635, 23637, 23641, 23651, 23657, 23663, 23667, 23668, 23670, 23682, 23683, 23698, 23699, 23702, 23710, 23711, 23712, 23728, 23734, 23735, 23738, 23760, 23763, 23774, 23791, 23796, 23803, 23806, 23822, 23823, 23836, 23841, 23848, 23855, 23866, 23874, 23878, 23880, 23881, 23882, 23884, 23888, 23889, 23896, 23909, 23932, 23942, 23947, 23949, 23951, 23973, 23979, 24000, 24006, 24009, 24025, 24026, 24031, 24036, 24038, 24040, 24041, 24046, 24058, 24061, 24062, 24064, 24073, 24074, 24075, 24079, 24088, 24096, 24103, 24105, 24107, 24110, 24129, 24145, 24161, 24169, 24172, 24174, 24178, 24196, 24198, 24203, 24206, 24207, 24208, 24213, 24214, 24215, 24219, 24224, 24230, 24231, 24234, 24236, 24238, 24243, 24248, 24252, 24258, 24265, 24266, 24280, 24289, 24297, 24298, 24302, 24303, 24306, 24309, 24310, 24316, 24328, 24341, 24343, 24350, 24358, 24360, 24362, 24371, 24387, 24390, 24391, 24401, 24404, 24405, 24421, 24422, 24436, 24437, 24443, 24444, 24448, 24452, 24456, 24458, 24460, 24461, 24462, 24463, 24464, 24465, 24467, 24474, 24480, 24481, 24482, 24496, 24515, 24528, 24533, 24544, 24562, 24564, 24565, 24576, 24580, 24583, 24587, 24591, 24592, 24596, 24600, 24606, 24619, 24624, 24642, 24661, 24681, 24686, 24688, 24689, 24694, 24700, 24701, 24705, 24722, 24724, 24725, 24727, 24729, 24731, 24749, 24760, 24765, 24776, 24778, 24796, 24799, 24810, 24819, 24823, 24830, 24835, 24843, 24861, 24863, 24864, 24887, 24899, 24915, 24916, 24917, 24924, 24928, 24932, 24942, 24945, 24953, 24961, 24964, 24966, 24968, 24977, 25003, 25011, 25012, 25018, 25021, 25028, 25032, 25048, 25058, 25060, 25072, 25073, 25074, 25088, 25101, 25108, 25111, 25135, 25137, 25147, 25152, 25154, 25159, 25161, 25167, 25176, 25181, 25182, 25185, 25188, 25190, 25198, 25205, 25208, 25209, 25210, 25214, 25215, 25223, 25225, 25226, 25231, 25242, 25251, 25260, 25273, 25278, 25287, 25295, 25296, 25300, 25310, 25317, 25324, 25327, 25336, 25337, 25342, 25345, 25348, 25365, 25370, 25377, 25381, 25384, 25386, 25406, 25412, 25414, 25436, 25439, 25446, 25459, 25460, 25465, 25477, 25478, 25479, 25482, 25483, 25484, 25489, 25493, 25494, 25509, 25512, 25516, 25525, 25536, 25537, 25545, 25555, 25566, 25570, 25572, 25575, 25592, 25593, 25594, 25601, 25619, 25625, 25635, 25645, 25646, 25648, 25655, 25659, 25663, 25666, 25677, 25691, 25702, 25703, 25705, 25707, 25721, 25724, 25728, 25732, 25753, 25754, 25755, 25756, 25759, 25771, 25773, 25775, 25779, 25794, 25796, 25798, 25801, 25820, 25822, 25837, 25844, 25848, 25855, 25856, 25857, 25864, 25871, 25878, 25880, 25884, 25888, 25916, 25917, 25918, 25930, 25933, 25942, 25944, 25973, 25975, 25976, 25994, 25997, 26004, 26008, 26011, 26012, 26020, 26029, 26030, 26034, 26038, 26042, 26044, 26052, 26056, 26068, 26070, 26072, 26073, 26075, 26080, 26083, 26085, 26086, 26104, 26111, 26118, 26129, 26133, 26136, 26138, 26144, 26162, 26178, 26180, 26182, 26187, 26188, 26189, 26200, 26216, 26219, 26230, 26237, 26239, 26245, 26248, 26254, 26255, 26260, 26273, 26279, 26284, 26291, 26301, 26308, 26318, 26325, 26331, 26340, 26345, 26346, 26347, 26348, 26350, 26374, 26378, 26380, 26387, 26398, 26402, 26405, 26407, 26408, 26417, 26420, 26424, 26432, 26434, 26437, 26443, 26444, 26450, 26466, 26469, 26471, 26497, 26511, 26513, 26522, 26523, 26524, 26528, 26529, 26535, 26553, 26567, 26575, 26588, 26594, 26619, 26629, 26631, 26635, 26638, 26642, 26647, 26657, 26663, 26665, 26669, 26691, 26692, 26694, 26697, 26699, 26710, 26711, 26713, 26721, 26723, 26724, 26734, 26749, 26754, 26759, 26764, 26767, 26770, 26774, 26779, 26787, 26788, 26789, 26796, 26814, 26822, 26825, 26827, 26829, 26841, 26846, 26857, 26859, 26860, 26868, 26870, 26871, 26873, 26874, 26898, 26913, 26922, 26925, 26928, 26931, 26932, 26943, 26944, 26945, 26953, 26957, 26968, 26970, 26977, 26978, 26981, 26992, 27001, 27002, 27007, 27008, 27011, 27012, 27020, 27025, 27030, 27031, 27047, 27054, 27061, 27062, 27071, 27074, 27077, 27084, 27086, 27091, 27096, 27103, 27115, 27121, 27124, 27128, 27133, 27134, 27136, 27145, 27152, 27164, 27171, 27173, 27195, 27206, 27215, 27216, 27226, 27247, 27249, 27268, 27272, 27293, 27298, 27305, 27306, 27309, 27338, 27339, 27343, 27345, 27347, 27350, 27356, 27357, 27358, 27362, 27364, 27365, 27366, 27373, 27377, 27382, 27394, 27403, 27414, 27417, 27429, 27434, 27439, 27443, 27448, 27450, 27451, 27454, 27469, 27470, 27474, 27476, 27479, 27482, 27485, 27486, 27489, 27497, 27501, 27508, 27518, 27521, 27524, 27526, 27544, 27552, 27565, 27567, 27568, 27571, 27585, 27592, 27597, 27623, 27647, 27651, 27653, 27656, 27661, 27671, 27672, 27673, 27694, 27697, 27698, 27707, 27715, 27724, 27727, 27735, 27744, 27746, 27747, 27755, 27765, 27777, 27783, 27785, 27786, 27793, 27796, 27799, 27807, 27811, 27814, 27815, 27817, 27819, 27823, 27832, 27837, 27840, 27846, 27856, 27872, 27873, 27876, 27877, 27882, 27886, 27895, 27916, 27921, 27931, 27934, 27938, 27951, 27957, 27960, 27963, 27965, 27966, 27971, 27977, 27978, 27981, 27988, 27991, 27992, 28000, 28005, 28020, 28022, 28023, 28043, 28044, 28045, 28047, 28050, 28053, 28058, 28065, 28073, 28080, 28081, 28092, 28100, 28134, 28137, 28142, 28144, 28153, 28157, 28158, 28168, 28174, 28177, 28178, 28188, 28189, 28194, 28211, 28230, 28231, 28232, 28248, 28251, 28255, 28263, 28265, 28267, 28269, 28275, 28284, 28288, 28291, 28304, 28311, 28312, 28318, 28323, 28330, 28334, 28335, 28337, 28347, 28349, 28352, 28356, 28366, 28377, 28384, 28389, 28391, 28405, 28410, 28411, 28416, 28432, 28433, 28438, 28440, 28441, 28447, 28450, 28453, 28455, 28458, 28465, 28471, 28474, 28475, 28488, 28493, 28497, 28501, 28505, 28506, 28509, 28513, 28517, 28525, 28526, 28538, 28540, 28541, 28557, 28558, 28574, 28580, 28587, 28588, 28589, 28592, 28596, 28597, 28602, 28605, 28607, 28610, 28611, 28614, 28616, 28619, 28620, 28625, 28628, 28636, 28642, 28647, 28651, 28655, 28658, 28671, 28684, 28695, 28700, 28704, 28707, 28711, 28728, 28731, 28743, 28745, 28749, 28758, 28759, 28761, 28763, 28773, 28774, 28782, 28784, 28798, 28800, 28803, 28808, 28818, 28821, 28823, 28841, 28842, 28847, 28852, 28853, 28857, 28858, 28861, 28866, 28881, 28892, 28904, 28905, 28924, 28926, 28935, 28945, 28946, 28956, 28957, 28959, 28960, 28968, 28972, 28982, 28988, 28996, 29006, 29008, 29016, 29019, 29021, 29026, 29029, 29037, 29040, 29046, 29048, 29054, 29060, 29063, 29065, 29067, 29069, 29088, 29091, 29092, 29093, 29099, 29100, 29101, 29103, 29117, 29119, 29126, 29135, 29137, 29152, 29154, 29155, 29164, 29165, 29175, 29181, 29183, 29191, 29192, 29199, 29202, 29208, 29209, 29223, 29232, 29254, 29264, 29267, 29268, 29276, 29277, 29281, 29291, 29296, 29301, 29308, 29318, 29320, 29330, 29333, 29334, 29335, 29345, 29346, 29350, 29363, 29364, 29373, 29400, 29401, 29407, 29412, 29414, 29416, 29418, 29421, 29425, 29436, 29449, 29457, 29466, 29472, 29473, 29482, 29487, 29488, 29489, 29498, 29507, 29508, 29509, 29514, 29517, 29518, 29526, 29536, 29537, 29543, 29552, 29573, 29577, 29578, 29580, 29582, 29592, 29593, 29594, 29598, 29604, 29609, 29615, 29620, 29622, 29626, 29632, 29638, 29649, 29656, 29659, 29661, 29666, 29677, 29687, 29690, 29708, 29716, 29728, 29732, 29739, 29745, 29755, 29758, 29760, 29764, 29766, 29780, 29791, 29792, 29793, 29794, 29801, 29802, 29803, 29807, 29809, 29811, 29812, 29813, 29815, 29821, 29824, 29827, 29828, 29835, 29847, 29851, 29861, 29865, 29874, 29878, 29881, 29885, 29908, 29916, 29917, 29925, 29929, 29931, 29932, 29936, 29940, 29951, 29959, 29966, 29974, 29975, 29979, 29980, 29983, 29986, 29988, 29992, 29996, 30014, 30018, 30031, 30035, 30036, 30040, 30042, 30044, 30053, 30064, 30066, 30068, 30071, 30072, 30076, 30079, 30083, 30091, 30094, 30095, 30099, 30102, 30105, 30107, 30110, 30111, 30118, 30122, 30123, 30128, 30140, 30147, 30155, 30156, 30158, 30175, 30185, 30190, 30192, 30204, 30205, 30211, 30213, 30214, 30226, 30229, 30234, 30236, 30246, 30265, 30277, 30278, 30285, 30286, 30287, 30292, 30304, 30310, 30315, 30332, 30348, 30357, 30358, 30360, 30363, 30366, 30383, 30399, 30411, 30412, 30418, 30420, 30424, 30425, 30437, 30446, 30448, 30453, 30479, 30483, 30484, 30486, 30488, 30501, 30503, 30508, 30515, 30519, 30520, 30522, 30525, 30529, 30538, 30539, 30545, 30548, 30559, 30563, 30565, 30568, 30571, 30583, 30585, 30591, 30593, 30599, 30614, 30616, 30618, 30622, 30623, 30637, 30645, 30671, 30673, 30693, 30698, 30699, 30704, 30706, 30719, 30721, 30725, 30731, 30736, 30738, 30750, 30754, 30764, 30774, 30784, 30788, 30793, 30797, 30802, 30810, 30812, 30813, 30822, 30829, 30830, 30834, 30838, 30844, 30851, 30852, 30861, 30862, 30873, 30877, 30878, 30880, 30885, 30898, 30903, 30907, 30911, 30913, 30921, 30924, 30925, 30930, 30944, 30949, 30953, 30954, 30974, 30988, 30994, 31003, 31008, 31010, 31015, 31020, 31024, 31034, 31040, 31048, 31053, 31054, 31056, 31065, 31075, 31080, 31088, 31089, 31090, 31091, 31098, 31099, 31101, 31102, 31103, 31107, 31113, 31115, 31119, 31122, 31127, 31134, 31135, 31143, 31149, 31152, 31159, 31166, 31167, 31168, 31171, 31175, 31189, 31206, 31221, 31222, 31241, 31244, 31248, 31250, 31252, 31261, 31263, 31264, 31269, 31270, 31273, 31275, 31278, 31288, 31294, 31295, 31296, 31297, 31299, 31304, 31305, 31306, 31308, 31309, 31314, 31315, 31325, 31334, 31342, 31361, 31376, 31382, 31391, 31396, 31398, 31399, 31403, 31407, 31409, 31412, 31430, 31438, 31442, 31446, 31449, 31461, 31476, 31479, 31488, 31489, 31509, 31518, 31523, 31529, 31530, 31543, 31549, 31562, 31563, 31565, 31569, 31583, 31585, 31587, 31589, 31594, 31595, 31617, 31621, 31628, 31632, 31635, 31647, 31657, 31671, 31673, 31681, 31692, 31701, 31712, 31713, 31715, 31725, 31727, 31752, 31757, 31758, 31775, 31783, 31792, 31796, 31808, 31828, 31831, 31832, 31839, 31841, 31843, 31846, 31853, 31856, 31872, 31874, 31881, 31884, 31901, 31911, 31914, 31924, 31925, 31933, 31939, 31943, 31945, 31948, 31950, 31955, 31958, 31961, 31972, 31973, 31989, 32007, 32008, 32012, 32015, 32020, 32028, 32066, 32082, 32090, 32092, 32093, 32095, 32103, 32115, 32116, 32127, 32128, 32130, 32135, 32142, 32145, 32149, 32153, 32158, 32160, 32161, 32165, 32171, 32172, 32174, 32190, 32193, 32201, 32202, 32209, 32211, 32213, 32217, 32224, 32227, 32229, 32236, 32245, 32249, 32256, 32263, 32267, 32269, 32274, 32278, 32279, 32280, 32281, 32288, 32301, 32312, 32317, 32318, 32332, 32333, 32339, 32355, 32363, 32368, 32370, 32382, 32391, 32398, 32405, 32407, 32415, 32417, 32419, 32420, 32422, 32424, 32434, 32458, 32467, 32480, 32482, 32491, 32498, 32503, 32507, 32508, 32514, 32515, 32516, 32517, 32526, 32556, 32560, 32572, 32575, 32585, 32586, 32588, 32589, 32590, 32594, 32602, 32605, 32608, 32609, 32621, 32634, 32635, 32636, 32645, 32654, 32658, 32667, 32670, 32682, 32686, 32688, 32707, 32728, 32729, 32731, 32734, 32746, 32757, 32758, 32760, 32761, 32764]\n",
      "\n",
      "=== Cluster 0 ===\n",
      "Size: 12 features (0.17% of total)\n",
      "Feature Indices: [1420, 2751, 5928, 7482, 14293, 17995, 18300, 22168, 25109, 30549, 30631, 31255]\n",
      "(7272, 1000)\n",
      "(7272,)\n",
      "\n",
      "Activation Statistics:\n",
      "  Mean Activation: 0.0005\n",
      "  Max Activation: 0.3649\n",
      "  Std Deviation: 0.0054\n",
      "  Sparsity: 0.0004\n",
      "\n",
      "Top 5 Activating Prompts:\n",
      "  1. \"Whatever happened to good old fashioned\"\n",
      "     Activation: 0.0844\n",
      "     Total Length: 39 chars, 6 tokens\n",
      "  2. \"instead , she had focused on getting good grades .\"\n",
      "     Activation: 0.0165\n",
      "     Total Length: 50 chars, 10 tokens\n",
      "  3. \" are nt you being a good boy ? \"\n",
      "     Activation: 0.0137\n",
      "     Total Length: 31 chars, 8 tokens\n",
      "  4. \"It seems that Damian is doing good not because of his values or own will ...\"\n",
      "     Activation: 0.0080\n",
      "     Total Length: 128 chars, 25 tokens\n",
      "  5. \"Wheres your better half ? Shes at home .\"\n",
      "     Activation: 0.0068\n",
      "     Total Length: 40 chars, 9 tokens\n",
      "\n",
      "=== Cluster 1 ===\n",
      "Size: 1784 features (24.53% of total)\n",
      "Feature Indices: [34, 68, 72, 96, 135, 145, 158, 166, 168, 185, 198, 220, 228, 231, 254, 256, 269, 296, 304, 324, 351, 371, 375, 378, 398, 414, 448, 453, 454, 461, 467, 544, 561, 578, 604, 636, 646, 655, 676, 677, 678, 713, 722, 775, 830, 834, 845, 852, 869, 870, 893, 937, 947, 965, 978, 981, 985, 995, 1007, 1034, 1047, 1052, 1055, 1060, 1064, 1084, 1151, 1158, 1159, 1164, 1165, 1166, 1176, 1208, 1214, 1224, 1296, 1321, 1339, 1358, 1363, 1365, 1371, 1372, 1389, 1393, 1395, 1435, 1436, 1439, 1440, 1465, 1467, 1477, 1517, 1520, 1524, 1533, 1534, 1587, 1609, 1610, 1671, 1683, 1739, 1758, 1780, 1783, 1792, 1816, 1819, 1831, 1836, 1846, 1878, 1881, 1883, 1918, 1932, 1958, 1975, 1978, 1981, 1991, 2056, 2074, 2078, 2089, 2113, 2174, 2203, 2223, 2229, 2244, 2247, 2250, 2251, 2259, 2266, 2287, 2292, 2293, 2316, 2342, 2357, 2366, 2391, 2418, 2419, 2443, 2482, 2553, 2612, 2690, 2692, 2701, 2729, 2754, 2761, 2763, 2772, 2778, 2781, 2801, 2818, 2874, 2888, 2908, 2909, 2938, 2984, 2990, 3020, 3038, 3049, 3050, 3066, 3077, 3078, 3096, 3135, 3165, 3173, 3176, 3177, 3181, 3225, 3244, 3290, 3306, 3317, 3318, 3335, 3342, 3354, 3366, 3432, 3452, 3465, 3496, 3530, 3543, 3602, 3623, 3642, 3649, 3652, 3673, 3693, 3731, 3747, 3777, 3782, 3793, 3802, 3808, 3814, 3823, 3833, 3834, 3847, 3858, 3860, 3866, 3950, 3959, 3964, 3979, 4013, 4024, 4072, 4074, 4121, 4169, 4199, 4206, 4264, 4293, 4337, 4365, 4393, 4432, 4475, 4478, 4491, 4529, 4531, 4535, 4568, 4583, 4597, 4614, 4624, 4646, 4663, 4667, 4669, 4731, 4766, 4776, 4791, 4810, 4823, 4871, 4877, 4892, 4910, 4959, 4983, 5040, 5043, 5049, 5060, 5090, 5111, 5125, 5132, 5167, 5168, 5169, 5187, 5193, 5254, 5284, 5289, 5299, 5335, 5348, 5369, 5379, 5381, 5385, 5393, 5400, 5429, 5434, 5439, 5471, 5483, 5487, 5496, 5499, 5504, 5532, 5533, 5535, 5540, 5541, 5558, 5581, 5603, 5630, 5682, 5705, 5711, 5726, 5753, 5755, 5759, 5766, 5792, 5798, 5800, 5826, 5848, 5884, 5886, 5914, 5920, 5951, 5953, 5976, 5986, 6007, 6010, 6023, 6072, 6110, 6140, 6149, 6167, 6171, 6172, 6185, 6189, 6220, 6247, 6254, 6271, 6285, 6292, 6303, 6338, 6470, 6477, 6482, 6486, 6498, 6537, 6587, 6624, 6629, 6639, 6643, 6645, 6677, 6705, 6719, 6724, 6750, 6763, 6837, 6883, 6884, 6885, 6920, 6943, 6969, 7002, 7026, 7027, 7065, 7068, 7080, 7095, 7122, 7130, 7132, 7202, 7205, 7313, 7318, 7324, 7342, 7362, 7363, 7368, 7378, 7399, 7434, 7494, 7495, 7506, 7508, 7512, 7514, 7537, 7558, 7569, 7585, 7590, 7595, 7625, 7661, 7672, 7714, 7716, 7731, 7762, 7764, 7775, 7791, 7793, 7802, 7803, 7815, 7876, 7916, 7930, 7951, 7962, 7992, 8002, 8005, 8024, 8027, 8044, 8054, 8061, 8075, 8077, 8086, 8091, 8130, 8170, 8173, 8182, 8217, 8219, 8234, 8245, 8249, 8252, 8297, 8310, 8316, 8358, 8382, 8395, 8404, 8406, 8426, 8455, 8463, 8464, 8480, 8527, 8548, 8582, 8583, 8596, 8604, 8616, 8664, 8691, 8704, 8709, 8735, 8774, 8779, 8792, 8851, 8867, 8876, 8880, 8894, 8900, 8929, 8930, 8989, 8999, 9006, 9043, 9056, 9107, 9111, 9123, 9133, 9134, 9161, 9206, 9212, 9219, 9227, 9241, 9267, 9273, 9279, 9289, 9312, 9325, 9345, 9357, 9384, 9400, 9418, 9426, 9466, 9490, 9502, 9553, 9579, 9580, 9584, 9590, 9595, 9597, 9616, 9635, 9641, 9649, 9655, 9687, 9689, 9696, 9699, 9730, 9733, 9762, 9797, 9820, 9890, 9898, 9984, 9991, 10002, 10012, 10027, 10045, 10053, 10054, 10111, 10114, 10169, 10170, 10196, 10222, 10229, 10260, 10318, 10329, 10341, 10379, 10395, 10426, 10433, 10434, 10442, 10452, 10453, 10475, 10477, 10488, 10505, 10521, 10542, 10546, 10594, 10598, 10606, 10608, 10610, 10697, 10703, 10712, 10725, 10740, 10741, 10756, 10782, 10823, 10841, 10847, 10851, 10863, 10887, 10889, 10895, 10900, 10907, 10908, 10913, 10961, 10983, 10995, 11022, 11033, 11038, 11048, 11093, 11097, 11118, 11137, 11167, 11202, 11211, 11222, 11228, 11229, 11233, 11243, 11283, 11291, 11298, 11301, 11325, 11362, 11364, 11390, 11392, 11484, 11515, 11524, 11543, 11650, 11659, 11669, 11671, 11678, 11681, 11687, 11730, 11731, 11749, 11764, 11789, 11806, 11808, 11827, 11829, 11857, 11858, 11870, 11880, 11882, 11893, 11927, 11970, 11993, 12006, 12015, 12020, 12044, 12053, 12077, 12088, 12100, 12101, 12117, 12185, 12198, 12200, 12201, 12204, 12235, 12246, 12259, 12264, 12282, 12312, 12321, 12343, 12351, 12358, 12385, 12439, 12444, 12446, 12470, 12520, 12526, 12576, 12579, 12590, 12651, 12680, 12699, 12718, 12748, 12750, 12752, 12758, 12762, 12818, 12822, 12825, 12832, 12857, 12866, 12884, 12908, 12926, 12952, 12972, 12975, 13006, 13061, 13116, 13117, 13140, 13151, 13154, 13158, 13194, 13206, 13220, 13221, 13223, 13227, 13231, 13262, 13304, 13330, 13351, 13366, 13384, 13395, 13450, 13452, 13472, 13539, 13603, 13619, 13662, 13669, 13683, 13737, 13755, 13760, 13762, 13785, 13789, 13804, 13848, 13870, 13872, 13873, 13879, 13932, 13945, 14004, 14019, 14069, 14070, 14102, 14156, 14167, 14179, 14206, 14223, 14226, 14267, 14279, 14305, 14333, 14362, 14371, 14381, 14383, 14416, 14423, 14440, 14458, 14462, 14470, 14471, 14477, 14480, 14499, 14511, 14515, 14524, 14533, 14545, 14552, 14566, 14575, 14598, 14621, 14623, 14629, 14635, 14638, 14644, 14651, 14655, 14656, 14664, 14676, 14741, 14754, 14821, 14864, 14876, 14888, 14892, 14940, 14957, 14969, 14972, 14989, 14997, 15044, 15059, 15073, 15163, 15169, 15199, 15231, 15287, 15289, 15322, 15385, 15412, 15418, 15473, 15485, 15488, 15496, 15503, 15520, 15526, 15530, 15551, 15553, 15555, 15597, 15600, 15608, 15630, 15651, 15659, 15663, 15664, 15720, 15745, 15763, 15768, 15770, 15771, 15783, 15827, 15831, 15838, 15852, 15863, 15873, 15876, 15902, 15907, 15922, 15938, 15943, 15964, 15997, 15998, 16011, 16052, 16066, 16068, 16087, 16116, 16146, 16170, 16196, 16210, 16217, 16233, 16262, 16281, 16287, 16291, 16311, 16342, 16392, 16402, 16421, 16450, 16467, 16515, 16529, 16549, 16583, 16591, 16631, 16649, 16654, 16674, 16711, 16766, 16769, 16781, 16892, 16898, 16903, 16923, 16950, 17002, 17004, 17023, 17024, 17041, 17074, 17094, 17126, 17149, 17159, 17167, 17171, 17206, 17313, 17321, 17326, 17384, 17427, 17428, 17485, 17487, 17527, 17580, 17582, 17601, 17622, 17646, 17654, 17656, 17660, 17664, 17668, 17673, 17682, 17698, 17708, 17734, 17738, 17748, 17775, 17791, 17795, 17838, 17848, 17860, 17864, 17867, 17876, 17921, 17952, 17976, 17979, 17989, 18022, 18037, 18043, 18068, 18075, 18102, 18108, 18112, 18121, 18132, 18135, 18146, 18154, 18160, 18173, 18190, 18253, 18255, 18287, 18306, 18312, 18313, 18325, 18334, 18337, 18377, 18391, 18413, 18431, 18440, 18452, 18473, 18487, 18546, 18574, 18582, 18607, 18628, 18643, 18662, 18671, 18706, 18734, 18744, 18746, 18847, 18853, 18874, 18900, 18903, 18939, 18981, 18988, 19015, 19078, 19079, 19157, 19159, 19172, 19183, 19207, 19218, 19221, 19276, 19296, 19338, 19356, 19361, 19369, 19378, 19389, 19457, 19469, 19478, 19521, 19567, 19584, 19593, 19599, 19626, 19642, 19652, 19654, 19662, 19698, 19711, 19728, 19740, 19761, 19772, 19805, 19815, 19823, 19855, 19864, 19870, 19888, 19906, 19945, 19962, 19964, 19984, 20023, 20035, 20039, 20052, 20053, 20069, 20102, 20110, 20146, 20154, 20160, 20200, 20210, 20226, 20229, 20279, 20292, 20293, 20309, 20378, 20438, 20502, 20507, 20510, 20529, 20534, 20570, 20586, 20593, 20706, 20726, 20737, 20742, 20746, 20844, 20872, 20881, 20890, 20893, 20900, 20926, 20937, 20953, 20958, 20974, 20977, 20993, 20997, 21000, 21006, 21008, 21029, 21049, 21062, 21082, 21093, 21098, 21112, 21118, 21121, 21135, 21185, 21215, 21257, 21284, 21293, 21319, 21362, 21374, 21378, 21388, 21435, 21443, 21484, 21491, 21511, 21512, 21516, 21522, 21528, 21538, 21572, 21588, 21591, 21615, 21631, 21654, 21659, 21677, 21686, 21746, 21787, 21810, 21821, 21835, 21844, 21854, 21856, 21860, 21862, 21932, 21955, 21964, 21979, 22007, 22016, 22053, 22084, 22088, 22090, 22091, 22093, 22145, 22153, 22155, 22163, 22210, 22238, 22243, 22255, 22296, 22298, 22323, 22339, 22344, 22347, 22366, 22369, 22370, 22377, 22386, 22413, 22422, 22426, 22432, 22440, 22463, 22494, 22497, 22501, 22504, 22575, 22582, 22593, 22616, 22617, 22622, 22624, 22632, 22665, 22681, 22710, 22728, 22752, 22797, 22800, 22826, 22827, 22844, 22848, 22851, 22857, 22864, 22867, 22887, 22906, 22909, 22964, 22997, 23008, 23017, 23018, 23021, 23022, 23025, 23037, 23055, 23057, 23075, 23082, 23089, 23104, 23149, 23164, 23169, 23172, 23220, 23261, 23276, 23278, 23279, 23280, 23286, 23348, 23395, 23426, 23460, 23474, 23507, 23511, 23518, 23528, 23537, 23552, 23556, 23586, 23618, 23625, 23626, 23631, 23632, 23636, 23639, 23648, 23658, 23676, 23709, 23719, 23749, 23750, 23798, 23805, 23810, 23812, 23831, 23849, 23862, 23900, 23906, 23938, 23940, 23950, 23952, 23959, 23970, 23978, 23998, 24037, 24039, 24067, 24076, 24111, 24112, 24131, 24155, 24157, 24168, 24176, 24183, 24194, 24255, 24264, 24270, 24299, 24331, 24339, 24368, 24408, 24427, 24440, 24472, 24478, 24488, 24512, 24523, 24549, 24554, 24561, 24569, 24589, 24608, 24645, 24646, 24649, 24702, 24715, 24777, 24802, 24832, 24838, 24940, 24941, 24943, 24976, 24979, 24980, 24985, 24995, 25031, 25091, 25114, 25124, 25130, 25163, 25166, 25172, 25211, 25234, 25253, 25256, 25322, 25341, 25367, 25379, 25455, 25500, 25544, 25551, 25595, 25597, 25621, 25637, 25651, 25675, 25715, 25744, 25767, 25778, 25785, 25793, 25809, 25812, 25817, 25841, 25858, 25874, 25891, 25896, 25921, 25928, 25943, 25951, 25959, 25962, 25965, 25970, 25999, 26077, 26113, 26114, 26127, 26132, 26134, 26135, 26204, 26214, 26225, 26227, 26241, 26250, 26259, 26274, 26280, 26287, 26295, 26311, 26353, 26363, 26368, 26377, 26410, 26414, 26428, 26438, 26449, 26516, 26531, 26533, 26544, 26555, 26573, 26581, 26582, 26585, 26590, 26610, 26636, 26643, 26654, 26660, 26700, 26702, 26722, 26735, 26736, 26761, 26795, 26820, 26833, 26883, 26885, 26946, 26995, 27029, 27095, 27100, 27125, 27126, 27178, 27186, 27218, 27270, 27278, 27316, 27318, 27380, 27400, 27401, 27438, 27494, 27495, 27516, 27531, 27532, 27534, 27554, 27583, 27605, 27618, 27648, 27682, 27685, 27695, 27737, 27741, 27754, 27818, 27830, 27868, 27870, 27878, 27888, 27892, 27899, 27958, 27970, 27979, 27996, 28004, 28019, 28042, 28062, 28087, 28121, 28123, 28132, 28165, 28169, 28182, 28204, 28223, 28226, 28240, 28244, 28294, 28308, 28319, 28320, 28331, 28340, 28362, 28394, 28395, 28401, 28415, 28420, 28428, 28429, 28448, 28481, 28482, 28485, 28508, 28516, 28529, 28542, 28552, 28553, 28595, 28617, 28634, 28643, 28648, 28649, 28656, 28680, 28716, 28767, 28804, 28815, 28817, 28854, 28872, 28873, 28887, 28890, 28922, 28938, 28940, 28955, 28958, 28981, 28987, 29020, 29041, 29077, 29105, 29123, 29131, 29167, 29243, 29246, 29251, 29253, 29263, 29366, 29404, 29445, 29465, 29511, 29521, 29529, 29531, 29533, 29535, 29540, 29548, 29554, 29562, 29569, 29595, 29597, 29641, 29670, 29714, 29727, 29734, 29763, 29767, 29771, 29774, 29808, 29814, 29820, 29822, 29838, 29886, 29930, 29939, 29956, 29963, 29978, 30067, 30069, 30073, 30092, 30119, 30126, 30142, 30148, 30179, 30184, 30191, 30202, 30216, 30218, 30233, 30253, 30257, 30260, 30274, 30280, 30301, 30306, 30320, 30321, 30337, 30439, 30445, 30461, 30482, 30497, 30504, 30530, 30536, 30537, 30541, 30552, 30580, 30584, 30659, 30670, 30683, 30691, 30733, 30734, 30740, 30741, 30746, 30760, 30765, 30780, 30789, 30821, 30870, 30889, 30923, 30934, 30936, 30959, 30964, 30973, 30975, 30980, 30985, 30995, 31005, 31007, 31027, 31045, 31049, 31097, 31110, 31120, 31131, 31150, 31162, 31163, 31173, 31197, 31249, 31251, 31259, 31266, 31274, 31279, 31282, 31300, 31301, 31324, 31327, 31330, 31346, 31358, 31360, 31363, 31389, 31404, 31433, 31457, 31458, 31463, 31464, 31477, 31486, 31499, 31548, 31564, 31596, 31656, 31674, 31735, 31801, 31812, 31819, 31892, 31903, 31967, 32018, 32034, 32035, 32048, 32057, 32067, 32073, 32091, 32102, 32117, 32170, 32175, 32197, 32226, 32286, 32292, 32306, 32307, 32311, 32374, 32384, 32399, 32401, 32436, 32451, 32469, 32529, 32537, 32558, 32568, 32574, 32583, 32591, 32595, 32619, 32627, 32646, 32732, 32738, 32745, 32747, 32753, 32763, 32765]\n",
      "(7272, 1000)\n",
      "(7272,)\n",
      "\n",
      "Activation Statistics:\n",
      "  Mean Activation: 0.0041\n",
      "  Max Activation: 0.8594\n",
      "  Std Deviation: 0.0117\n",
      "  Sparsity: 0.0022\n",
      "\n",
      "Top 5 Activating Prompts:\n",
      "  1. \"Fairyopolis  Frederick Warne , 2005\"\n",
      "     Activation: 0.0085\n",
      "     Total Length: 35 chars, 5 tokens\n",
      "  2. \"Robert Herrick may refer to Robert Herrick novelist 18681938, American novelist Robert Herrick poet ...\"\n",
      "     Activation: 0.0079\n",
      "     Total Length: 122 chars, 17 tokens\n",
      "  3. \"A Flower Fairies Treasury  Frederick Warne , 1997\"\n",
      "     Activation: 0.0075\n",
      "     Total Length: 49 chars, 8 tokens\n",
      "  4. \"Beautiful Bible Pictures  Blackie , 1932\"\n",
      "     Activation: 0.0070\n",
      "     Total Length: 40 chars, 6 tokens\n",
      "  5. \"A Flower Fairy Alphabet  Blackie , 1934\"\n",
      "     Activation: 0.0069\n",
      "     Total Length: 39 chars, 7 tokens\n",
      "\n",
      "=== Cluster 2 ===\n",
      "Size: 11 features (0.15% of total)\n",
      "Feature Indices: [7818, 18161, 19293, 22211, 22737, 24913, 25288, 27668, 28850, 29587, 31755]\n",
      "(7272, 1000)\n",
      "(7272,)\n",
      "\n",
      "Activation Statistics:\n",
      "  Mean Activation: 0.0006\n",
      "  Max Activation: 0.2761\n",
      "  Std Deviation: 0.0060\n",
      "  Sparsity: 0.0005\n",
      "\n",
      "Top 5 Activating Prompts:\n",
      "  1. \"It is important to be more careful, the more you eat.\"\n",
      "     Activation: 0.0842\n",
      "     Total Length: 53 chars, 11 tokens\n",
      "  2. \"It is important for the more you to eat, the more careful for you to ...\"\n",
      "     Activation: 0.0545\n",
      "     Total Length: 72 chars, 16 tokens\n",
      "  3. \"It is important the more you eat, the more careful to be.\"\n",
      "     Activation: 0.0500\n",
      "     Total Length: 57 chars, 12 tokens\n",
      "  4. \"It is not entirely obvious if, Mary listens to the Grateful Dead, she gets depressed.\"\n",
      "     Activation: 0.0218\n",
      "     Total Length: 85 chars, 15 tokens\n",
      "  5. \"Please excuse me , but I really have to be going . Yes , of ...\"\n",
      "     Activation: 0.0106\n",
      "     Total Length: 164 chars, 37 tokens\n",
      "\n",
      "=== Cluster Similarity Analysis ===\n"
     ]
    }
   ],
   "source": [
    "# Track results for each cluster\n",
    "cluster_analysis = {}\n",
    "\n",
    "# Get unique valid cluster labels (including noise points)\n",
    "all_labels = np.unique(labels)\n",
    "unique_labels = [label for label in all_labels if label != -1]\n",
    "\n",
    "# Calculate global statistics\n",
    "total_features = len(labels)\n",
    "noise_points = np.sum(labels == -1)\n",
    "noise_ratio = noise_points / total_features if total_features > 0 else 0\n",
    "\n",
    "print(f\"\\n=== Cluster Analysis Summary ===\")\n",
    "print(f\"Total Features: {total_features}\")\n",
    "print(f\"Number of Clusters: {len(unique_labels)}\")\n",
    "print(f\"Noise Points: {noise_points} ({noise_ratio:.2%})\")\n",
    "\n",
    "# For each cluster (including noise)\n",
    "for label in all_labels:\n",
    "    cluster_type = \"Noise Cluster\" if label == -1 else f\"Cluster {label}\"\n",
    "    cluster_mask = labels == label\n",
    "    cluster_size = np.sum(cluster_mask)\n",
    "    cluster_indices = original_indices[cluster_mask]\n",
    "    \n",
    "    print(f\"\\n=== {cluster_type} ===\")\n",
    "    print(f\"Size: {cluster_size} features ({(cluster_size/total_features):.2%} of total)\")\n",
    "    print(f\"Feature Indices: {cluster_indices.tolist()}\")\n",
    "    \n",
    "    if label == -1:  # Skip activation analysis for noise cluster\n",
    "        cluster_analysis[label] = {\n",
    "            'size': cluster_size,\n",
    "            'indices': cluster_indices.tolist(),\n",
    "            'ratio': cluster_size/total_features,\n",
    "            'is_noise': True\n",
    "        }\n",
    "        continue\n",
    "        \n",
    "    # Get activations for all prompts on this cluster's features\n",
    "    print(reduced_acts.shape)\n",
    "    print(cluster_mask.shape)\n",
    "    cluster_acts = filtered_acts[:, cluster_mask]  # [n_prompts, n_cluster_features]\n",
    "    \n",
    "    # Compute activation statistics\n",
    "    mean_activation = torch.mean(torch.abs(cluster_acts)).item()\n",
    "    max_activation = torch.max(torch.abs(cluster_acts)).item()\n",
    "    std_activation = torch.std(torch.abs(cluster_acts)).item()\n",
    "    sparsity = (torch.abs(cluster_acts) > 0.1).float().mean().item()\n",
    "    \n",
    "    print(f\"\\nActivation Statistics:\")\n",
    "    print(f\"  Mean Activation: {mean_activation:.4f}\")\n",
    "    print(f\"  Max Activation: {max_activation:.4f}\")\n",
    "    print(f\"  Std Deviation: {std_activation:.4f}\")\n",
    "    print(f\"  Sparsity: {sparsity:.4f}\")\n",
    "    \n",
    "    # Compute average activation of each prompt on this cluster's features\n",
    "    prompt_activations = torch.mean(torch.abs(cluster_acts), dim=1)  # [n_prompts]\n",
    "    \n",
    "    # Find top activating prompts\n",
    "    top_k = min(5, len(prompts))\n",
    "    top_prompt_indices = torch.argsort(prompt_activations, descending=True)[:top_k]\n",
    "    top_prompts = [(prompts[i], prompt_activations[i].item()) for i in top_prompt_indices]\n",
    "    \n",
    "    print(f\"\\nTop {top_k} Activating Prompts:\")\n",
    "    for i, (prompt, act) in enumerate(top_prompts, 1):\n",
    "        # Show first 100 chars, with special formatting for section headers\n",
    "        truncated = prompt[:100]\n",
    "        if len(prompt) > 100:\n",
    "            truncated += \"...\"\n",
    "        \n",
    "        # Format section headers more clearly\n",
    "        if \"=\" in truncated:\n",
    "            sections = [s.strip() for s in truncated.split(\"=\") if s.strip()]\n",
    "            if sections:\n",
    "                truncated = f\"[SECTION] {' > '.join(sections)}\"\n",
    "        \n",
    "        # Split into tokens if the prompt contains spaces\n",
    "        tokens = truncated.split()\n",
    "        if len(tokens) > 15:\n",
    "            token_display = \" \".join(tokens[:15]) + \" ...\"\n",
    "        else:\n",
    "            token_display = truncated\n",
    "            \n",
    "        print(f\"  {i}. \\\"{token_display}\\\"\")\n",
    "        print(f\"     Activation: {act:.4f}\")\n",
    "        print(f\"     Total Length: {len(prompt)} chars, {len(prompt.split())} tokens\")\n",
    "    # Store detailed results\n",
    "    cluster_analysis[label] = {\n",
    "        'size': cluster_size,\n",
    "        'indices': cluster_indices.tolist(),\n",
    "        'ratio': cluster_size/total_features,\n",
    "        'is_noise': False,\n",
    "        'mean_activation': mean_activation,\n",
    "        'max_activation': max_activation,\n",
    "        'std_activation': std_activation,\n",
    "        'sparsity': sparsity,\n",
    "        'top_prompts': top_prompts,\n",
    "        'prompt_activations': prompt_activations.cpu().numpy()\n",
    "    }\n",
    "\n",
    "\n",
    "# Print cluster similarity analysis\n",
    "if len(unique_labels) > 1:\n",
    "    print(\"\\n=== Cluster Similarity Analysis ===\")\n",
    "    for i, label1 in enumerate(unique_labels):\n",
    "        for label2 in unique_labels[i+1:]:\n",
    "            acts1 = cluster_analysis[label1]['prompt_activations']\n",
    "            acts2 = cluster_analysis[label2]['prompt_activations']\n",
    "            correlation = np.corrcoef(acts1, acts2)[0, 1]\n",
    "            if abs(correlation) > 0.5:  # Only show significant correlations\n",
    "                print(f\"Clusters {label1} and {label2}: correlation = {correlation:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
